\chapter{Experiments and Results}
\label{C:Experiments}

In order to demonstrate that the algorithms we propose are superior to 
similar algorithms in the field, we will have to compare them with the 
state of the art. In this chapter we will first describe exactly how we 
intent to compare the algorithms and then discuss the results of these 
comparisons.  

\section{Experiments}
These requirements we expect from a matching algorithm fall in to three 
categories.  We want to the algorithm to be \emph{general}, 
\emph{accurate} and \emph{fast}. In the experiments we hope to measure 
how \emph{MM} and \emph{MMC} perform on those three accounts compared to
\emph{Ratio}, \emph{Isomatch} and \emph{Spectral}.

\subsection{Measuring Generality}

To convincingly show that the algorithms work for general cases we need 
to demonstrate good results across a wide range of images.  However if 
we are just given two images and a set of matches, there is no
way to tell which matches are correct and which aren't without going 
through the output by hand and for each match verify that it is correct.  
For any but the simplest cases this becomes prohibitively time 
consuming.

\begin{figure}[tb]
    \begin{subfigure}[t]{0.5\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/homography_possible}
        \caption{Homography possible}
        \label{fig:hom_possible}
    \end{subfigure}%
        \quad %add desired spacing between images, e. g. ~, \quad, (or a 
    %blank line to force the subfigure onto a new line)
    \begin{subfigure}[t]{0.5\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/homography_not_possible}
        \caption{Homography not possible}
        \label{fig:hom_impossible}
    \end{subfigure}%
    \caption{Example of images that can and cannot be tied with a 
        homography: Figure~\ref{fig:hom_possible} shows an image pair 
        that can be linked by a homography, since all common areas lie 
        on a plane.  Figure~\ref{fig:hom_impossible} shows an image pair 
        that cannot reliably be linked by a homography. Even if we 
        discount the change of people in the scence, the position of the 
        bell compared to the building in the background changes as we 
        change our viewpoint. Images in Figure~\ref{fig:hom_possible} 
    are from the \emph{Murals} dataset while images in 
Figure~\ref{fig:hom_impossible} are from the Gallagher dataset 
\cite{gallagher2008}.}
    \label{fig:homography_example}
\end{figure}

A way to circumvent this problem is to restrict the images we test on to 
image pairs that are linked by a homography. Two images linked by a 
homography are related in a way that means that any point in the first 
image can be translated a point in the second by a affine equation. This 
holds true for two images where the points they have in common are 
situated on a plan, or in the case that the camera only rotated in 
between images.  Figure~\ref{fig:homography_example} shows an example of 
an image pair that can be linked with a homography and another that 
cannot. In the second image pair, the change in camera position means 
that pixels cannot be linearly translated from one image to another. For 
example a pixel on the bell would be translated to one location while an 
adjacent pixel on the building in the background would
move differently. For this reason we are constrained in which images 
it's possible to test the algorithms on since we cannot evaluate the 
results if the images are not tied by a homography.

Mikolajczyk and Schmid  \cite{mikolajczyk2005performance} introduced a 
set of test images to compare the performance of feature detectors. The 
set covers different types of image variations, such as lighting change, 
blur, rotation, and viewpoint change. Inspired by this dataset (in 
particular the `\emph{Graf}' image set) and motivated by the need for 
more image pairs featuring viewpoint changes, we have compiled a set of 
8 image pairs consisting of subjects taken from two different angles.  
The images are collected from \emph{Flickr's} database of images 
published under a \emph{Creative Commons Licence} and feature murals, 
which makes it possible to relate points in the image pairs with a 
homography since most of the points in the images will be lying on a 
plane.  The images have been cropped to show the same motive and resized 
to $900\times 600$ pixels.  This dataset will be referred to as the 
\emph{Murals} dataset.  Figure~\ref{fig:murals} shows one image from 
each pair.

\begin{figure}[b]
    \begin{subfigure}[t]{0.102\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/pair_example1}
    \end{subfigure}%
		\enspace %add desired spacing between images, e. g. ~, \quad, 
		%(or a blank line to force the subfigure onto a new line)
    \begin{subfigure}[t]{0.102\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/pair_example2}
    \end{subfigure}%
    \enspace %
    \begin{subfigure}[t]{0.77\textwidth}
    \centering
    \includegraphics[width=\columnwidth]{images/crop_examples}
    \end{subfigure}%
    \caption{Sample test patches produced from an image pair.}
	\label{fig:fairey}
\end{figure}

\begin{figure*}[t]
	\centering
	\includegraphics[width=\textwidth]{images/murals}
	\caption{Images in the \emph{Murals} test set.}
	\label{fig:murals}
\end{figure*}

\begin{figure}[tb]
	\centering
	\includegraphics[width=\columnwidth]{images/graf12345.jpg}
	\caption{Images 1-5 of the Graf set from \cite{mikolajczyk2005performance}.}
	\label{fig:Graf}
\end{figure}

To increase the generality of the image pairs to cases that partially 
overlap or have no overlap at all, we generated test sets from the image 
pairs by cropping square patches of $250\!\times\!250$ pixels with a 
random vertical and horizontal offset.  Given a source image pair, we 
produce 100 pairs of patches that might or might not overlap.  This 
ensures that patch pairs with no overlap still retain a general 
similarity to each other, while patches that do overlap often only share 
a small part of their area.  Figure~\ref{fig:fairey} shows an example of 
possible pairs of test image patches produced from a source image pair.  
Producing $n$ such pairs allows us to test not just how well the 
matching algorithm performs on a variety of overlaps but also how many 
false positives we get on similar images that do not overlap at all. In 
practice the amount of overlap between pairs in a test set will depend 
on the overlap and viewpoint change in the source image pair.  To give a 
rough idea, Table~\ref{table:overlap} shows the overlap of patch pairs 
created from images 1 and 3 of the \emph{Graf} image set from 
\cite{mikolajczyk2005performance}.

In addition to the \emph{Murals} data set we created a similar test set
based on the the \emph{Graf} set (Figure~\ref{fig:Graf}) showing 
different amounts of viewpoint change. A more typical real life test 
case was created as well using two images\footnote{100\_1942.jpg and 
100\_1941.jpg} (\emph{Pitts}) from the Gallagher dataset 
\cite{gallagher2008} (Figure~\ref{fig:comparemirror}). These two images 
are typical holiday shots and feature occlusion as well as a slight 
change in perspective.

\begin{table}[htb]
\caption{Overlap in the set of 100 patch pairs created from two images 
of the \emph{Graf} image set (Figure~\ref{fig:Graf}).}
\label{table:overlap}
    \centering
%   \small
\begin{tabular}{r*{3}{r}}
\hline
    Amount of overlap: & 0\% & $< 50$\% & $> 50$\%  \\
    \noalign{\smallskip}
	%
    Number of patch pairs: & 21 & 54 & 25 \\
    \hline
\end{tabular}
\end{table}

\subsection{Measuring Accuracy}

To measure the accuracy of an algorithm we are interested in two values:
Recall and Precision. These measures were introduced in \cite{ke2004pca}
and later used in \cite{mikolajczyk2005performance}. Recall corresponds 
to the number of correct matches over the total amount of possible 
correct matches in between the two images:
\begin{equation*}
	Recall = \frac{\# ~ Correct ~ Matches}{\# ~ Total ~ Possible ~ 
	Matches}
\end{equation*}
This measure tells us how thorough we are in finding all possible 
matches that could be made between the two images. To decide whether a 
match is correct, we use the following method:
Given a potential match between two pixels $p_1$ and $p_2$, $m = 
\left(p_1, p_2\right)$, and a homography $H$ relating the two images 
$I_1$ and $I_2$, we can calculate if $m$ is an inlier by checking if the 
two points satisfy the following criteria:
\begin{equation*}
\left\vert H p_1 - p_2 \right\vert + \left\vert H^{-1}p_2 - p_1 \right\vert < d_{\max}
\end{equation*}
That is, the distance between $p_1$ translated to $I_2$ and $p_2$ 
\emph{plus} the distance between $p_2$ translated to $I_1$ should be 
less than a certain threshold (we use $d_{\max}=5$ pixels here). To 
count the number of possible matches we go over all possible 
combinations of feature points between the two images, measure their 
distance and count how many lie within the threshold.
Precision on the other hand is measured by the amount of correct matches
over the total amount of matches returned:
\begin{equation*}
	Precision = \frac{\# ~ Correct ~ Matches}{\# ~ Correct ~ Matches ~ + 
	~ \# ~ False ~ Matches}
\end{equation*}
This measures how accurate the set of returned matches from the 
algorithm is. An algorithm that returns only a few matches out of many, 
but most of them are correct will have a high Precision and a low 
Recall, where as an algorithm that returns almost all possible matches, 
both true and false will have a low Precision but a high Recall. The 
ideal matching algorithm will be both precise but also return as many 
correct matches as possible. However for many applications we only need 
enough correct matches to align to the images, in which case we care 
more about Precision than Recall. 
%
\subsection{Measuring Speed}
%
To gain an intuition about the typical running time of an algorithm we 
need to understand how the speed of the algorithm varies with different 
input lengths (i.e.\ pictures of different sizes in our case) as well as 
a general idea of how long it takes the algorithm to run given inputs of
a typical case. The first is usually denoted the computational 
complexity of the algorithm, while the second is a measure of speed.

Once we know how long it will take the algorithm to run for inputs of a 
certain size we can use the complexity to extrapolate how much longer it
will take to run for inputs of e.g.\ double or half that size. For this 
reason we will have to look at both the measuring speed as well
as the computational complexity of the algorithms.
%
\begin{figure}[t]
    \centering
    \begin{subfigure}[c]{0.18\textwidth}
        \includegraphics[width=\textwidth]{images/graf}
	\end{subfigure}%
	~ %add desired spacing between images, e. g. ~, \quad, \qquad		  
	%(or a blank line to force the subfigure onto a new line)
    \begin{subfigure}[c]{0.76\textwidth}
%    \centering
	\includegraphics[width=\columnwidth]{images/result_graf}
	%\caption{Performance on Scharf}
	\end{subfigure}%
	\caption{Accuracy for image pair 1\&3 from the \emph{Graf} set. The 
	plot shows the result of 100 patch pairs generated from the source 
	images shown to the left. The x-axis shows the Recall based on the 
accumulated amount of potential matches for all 100 patch pairs. }
	\label{fig:result_graf}
\end{figure}
%
\section{Results}
\label{S:Results}
%
Using the \emph{Murals} dataset as well as test sets created from the 
\emph{Graf} and \emph{Pitts} images we tested \emph{MM} and \emph{MMC} 
against \emph{Ratio}, \emph{Spectral} and \emph{Isomatch}.
%
\subsection{Accuracy and Generality}
%
Figure~\ref{fig:result_graf} shows the results for 100 patch pairs 
generated from images 1 and 3 of the \emph{Graf} image set 
(cf.~Figure~\ref{fig:Graf}). The plot compares the accuracy of 
\emph{Ratio}, \emph{MM}, \emph{MMC}, \emph{Isomatch} and \emph{Spectral} 
as a function of the number of matches produced (which is achieved by 
varying thresholds over a certain range). The results show that 
\emph{MM} and \emph{MMC} consistently outperform \emph{Ratio}, 
\emph{MMC} generally lies 2-3 percentage points above \emph{MM} when 
both are performing at optimal accuracy.  The geometric matching methods 
\emph{Isomatch} and \emph{Spectral} outperform \emph{Ratio} but fall 
short of \emph{MM} and \emph{MMC}.

To validate whether these results generalize to other images, we tested 
the four algorithms on the \emph{Murals} dataset as well as the 
\emph{Graf} pair tested above.  In total 900 different patch pairs were 
generated from 9 source image pairs.  The results are shown in Figure 
\ref{fig:result_accumulated}. 
%
\begin{figure}[htb]
	\centering
    \includegraphics[width=0.9\columnwidth]{images/result_accumulated}
	\caption{Results for 900 patch pairs extracted from the 
	\emph{Murals} dataset and the image pair 1\&3 from the \emph{Graf} 
	set.  The x-axis shows the Recall based on the accumulated amount of 
potential matches for all patch pairs.}
	\label{fig:result_accumulated}
\end{figure}
%
\begin{figure}[htb]
	\centering
    \includegraphics[width=0.9\textwidth]{images/result_viewpoint}
    \caption{Results for viewpoint changes using the \emph{Graf} set 
    from \cite{mikolajczyk2005performance}.  S: img1 \& 2; M: img1 \& 3; 
    L: img1 \& 4; XL: img1 \& 5.}
	\label{fig:result_viewpoint}
\end{figure}
%
\begin{figure}[htb]
	\centering
    \includegraphics[width=0.9\textwidth]{images/result_spectral-mmc}
	\caption{Results for filtering matches with \emph{MMC} before 
	applying the \emph{Spectral} algorithm. The algorithm is tested on 
900 patch pairs extracted from the \emph{Murals} dataset and the image 
pair 1\&3 from the \emph{Graf} set. The x-axis shows the Recall based on 
the accumulated amount of potential matches for all patch pairs.}
	\label{fig:result_spectral-mmc}
\end{figure}
%
To further investigate the impact of viewpoint changes, we tested the 
algorithms on the \emph{Graf} image set (Figure~\ref{fig:Graf}), which 
contains 5 images of the same mural taken with gradually increasing 
viewpoint changes.  The first images are almost identical, while the 
last are taken from increasingly different angles. The results from   
\emph{MMC} and \emph{Ratio} as shown in 
Figure~\ref{fig:result_viewpoint}, confirm that \emph{MMC} is generally 
superior to \emph{Ratio} across viewpoint changes. For both methods 
however we see a stark decrease in Recall as the viewpoint change 
increases. The performance of \emph{MM} (not shown in the plot) is 
similar to \emph{MMC}.


In order to investigate whether a geometric algorithm can be improved by
pruning the initial matching set, we tested a hybrid algorithm 
\emph{Spectral-MMC} where matches are selected by \emph{MMC} before 
being filtered by \emph{Spectral}. The results are shown in 
Figure~\ref{fig:result_spectral-mmc} and show that \emph{Spectral-MMC} 
not only outperforms \emph{Spectral} but also improves on \emph{MMC} at 
similar Recall rates, illustrating how a geometric algorithm can be 
complemented by a reliable non-geometric selection of matches.


Finally, as an example of a real life use case, 
Figure~\ref{fig:result_pitts} shows the results on 100 patch pairs 
generated from a typical holiday photo shot 
(Figure~\ref{fig:pitts_source}) featuring occlusion and a slight 
viewpoint change from the \emph{Gallagher} dataset \cite{gallagher2008}.  
The performance is comparable to the murals, despite the lack of a 
simple homographic mapping between the images.
%
\begin{figure}[htb]
    \centering
    \begin{subfigure}[c]{.18\textwidth}
        \includegraphics[width=\textwidth]{images/pitts}
	\end{subfigure}%
	~%add desired spacing between images, e. g. ~, \quad, \qquad
	%(or a blank line to force the subfigure onto a new line)
    \begin{subfigure}[c]{.76\textwidth}
    \includegraphics[width=1\columnwidth]{images/result_pitts}
	\end{subfigure}%
	\caption{Results for 100 patch pairs based on the image pair in 
	Figure~\ref{fig:pitts_source}.}
	\label{fig:result_pitts}
\end{figure}
%
\subsection{Computational Complexity and Speed}
%
\begin{table}[htb]
\caption{Running times as tested on a Intel\textregistered\ Core\texttrademark\ i5-3550 CPU @ 
3.30~GHz with 8~GB memory.}
\label{table:running_times}
	\centering
%	\small
\begin{tabular}{r*{5}{c}}
\hline
	Algorithm: & \emph{Ratio} & \emph{MM} & \emph{MMC} %
& \emph{Isomatch} & \emph{Spectral}	\\
	\noalign{\smallskip} 
	%
	Running time (seconds): & 21 & 23 & 2722 & 1146 & 994\\
	\hline
\end{tabular}
\end{table}
In terms of computational complexity, \emph{Ratio}, \emph{MM}, and 
\emph{Isomatch} can be implemented in $O(n\log n)$, where $n$ is the 
total number of feature points. The performance of \emph{Spectral} is 
upper bounded by $O(n^{3/2})$. Our current \emph{MMC} implementation has 
a complexity of $O(n^2)$ due to the construction of a similarity matrix 
of the feature points.  However, it is possible to approximate this in 
$O(n\log n)$ using search trees.  

As for speed, Table~\ref{table:running_times} shows the running time of 
the four algorithms over 100 image pairs of $250\!\times\!250$ pixels.  
These numbers should be taken with a grain of salt, given that much of 
the code behind \emph{MMC} and \emph{Isomatch} is implemented in 
\emph{Python}, whereas \emph{MM} and \emph{Ratio} make use of 
\emph{OpenCV} to execute computationally intensive operations in 
\emph{C++}, which makes them much faster. 

