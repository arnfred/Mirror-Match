%\documentclass[report]{IEEEtran}
\documentclass{article}
\usepackage{footnote}
%\usepackage[font={small}]{caption}
\usepackage{sidecap}
\usepackage{graphicx}
\usepackage{cite}
\usepackage{hyperref}
%\usepackage[stable]{footmisc}
\usepackage{caption}
\usepackage{adjustbox}
\usepackage{subcaption}
\usepackage{algpseudocode}
\usepackage{algorithm}
\usepackage{amsmath}
\usepackage{amssymb}

\begin{document}

\title{Reliable feature point matching}
\author{Jonas Arnfred}

\maketitle

\section{Introduction}
What is the subject of this thesis and in what part lies my 
contribution?
How is the report organized?

\section{Background}
Introduction to Computer Vision
 - Introduce common tasks that we are good at that computers aren't
 - Single in on tasks that we can solve using feature points

Introduction to feature points
 - Global explanation of what they are and how they serve to solve the 
problems mentioned before
 - How do we find them? (Examples making it intuitive why corners are 
nice)
 - How do we describe them? (Relate invariance: Light, Rotation, Noise, 
 Scale, \ldots, Affine)
 - Introduce SIFT and explain how the different problems are tackled in 
SIFT)
 - Talk about other methods and how they are different

Matching feature points
 - What applications require matching?
 - How is matching usually done
 - Segue into related work from paper

\section{Matching feature points}
Basically c/p from paper, but better figures and maybe more explanations
 - Add path about graphs and how they are formed. Make sure to explain 
 the clustering in more detail and make it easier to understand
 - Add a good explanation for new figures and how the precision and 
 recall are calculated. This should appear somewhere before results.
 - Add part on spectral matching and modify accordingly. Make sure to 
 underline how the second plot shows how the geometric method is 
 independent of MMC and that they combined yield greater results.

\subsection{Proposed Matching Methods}
\label{S:MatchingMethods}

\subsubsection{Mirror Match (\emph{MM})}

\begin{figure}
	\centering%
		\begin{subfigure}[t]{\columnwidth}
			\centering
			\includegraphics[width=0.85\columnwidth]{images/MMC_pitts_source}
			\caption{Source image pair}
			\label{fig:pitts_source}
		\end{subfigure}%
		\\ %
		\begin{subfigure}[t]{\columnwidth}
			\centering
			\includegraphics[width=0.85\columnwidth]{images/MMC_pitts_keypoints}
			\caption{Feature points}
			\label{fig:pitts_keypoints}
		\end{subfigure}%
		\\ %add desired spacing between images, e. g. ~, \quad, 
		%\qquad (or a blank line to force the subfigure onto a new line)
		\begin{subfigure}[t]{\columnwidth}
			\centering
			\includegraphics[width=0.85\columnwidth]{images/mirror_match_off}
			\caption{\emph{SIFT}}
			\label{fig:unique}
		\end{subfigure}%
		\\ %add desired spacing between images, e. g. ~, \quad, 
		\begin{subfigure}[t]{\columnwidth}
			\centering
			\includegraphics[width=0.85\columnwidth]{images/mirror_match_with_pruned}
			\caption{\emph{MM} intermediate result}
			\label{fig:within}
		\end{subfigure}%
		\\ %add desired spacing between images, e. g. ~, \quad, 
		%\qquad (or a blank line to force the subfigure onto a new line)
		\begin{subfigure}[t]{\columnwidth}
			\centering
			\includegraphics[width=0.85\columnwidth]{images/mirror_match}
			\caption{\emph{MM} final result}
			\label{fig:without}
		\end{subfigure}%
		\\ %add desired spacing between images, e. g. ~, \quad, 
		\begin{subfigure}[t]{\columnwidth}
			\centering
			\includegraphics[width=0.85\columnwidth]{images/MMC_partition}
			\caption{\emph{MMC} Partition Example}
			\label{fig:pitts_partition}
		\end{subfigure}%
	\caption{Feature matching with \emph{MM} and \emph{MMC}. Dots represent feature points; green/red lines indicate correct/incorrect matches, respectively; black lines represent edges in the feature graph.  
	(c) Result of \emph{SIFT} matching. 
  (d) All matches found by \emph{MM}, including intra-image matches. 
	(e) Final \emph{MM} result. 
	(f) Example of a partition of feature points after clustering, which 
includes similar feature points from building windows and shirt patterns.}%
	\label{fig:comparemirror}%
\end{figure}%


%
The central idea behind \emph{MM} is to match features of $n$ images by 
taking every feature from all $n$ images and matching it against every 
other feature from the same set. We can then discard the correspondences 
that match two points within the same image. Algorithm~\ref{alg-mm} details  
the implementation of \emph{MM}.
%
\begin{algorithm}
\caption{Mirror Match (\emph{MM})}
\label{alg-mm}
%{\fontsize{10}{10}\selectfont
\begin{algorithmic}
\Require $images$ : set of images, $t \in \mathbb{R}$
\State $matches_{init}\gets \varnothing$
\State $matches_{final}\gets \varnothing$
\State $features\gets \varnothing$
\ForAll{$I_i \in images$} \Comment Acquisition Stage
	\State $features\gets features \cup getFeatures(I_i)$
\EndFor
\ForAll{$f_i \in features$} \Comment Matching Stage
	\State $f_m,f_n \gets get2NNs(f_i, features \setminus 
	\left\{f_i\right\})$
	\State $ratio \gets similarity(f_i, f_n) / similarity(f_i, f_m)$
	\If{$ratio < t$}
		\State $matches_{init} \gets \left(f_i, f_m\right)$
	\EndIf
\EndFor
\ForAll{$\left(f_i, f_j \right) \in matches_{init}$} \Comment Filter 
Stage
\If{$\left(f_j, f_i \right) \in matches_{init} \wedge getImg(f_i) \neq 
getImg(f_j) \wedge \left(f_j, f_i\right) \not\in matches_{final}$}
		\State $matches_{final} \gets (f_i, f_j)$
	\EndIf
\EndFor \\
\Return $matches_{final}$
\end{algorithmic}
%}
\end{algorithm}
%
In the acquisition stage we gather all features in the set of images.  
In the matching stage these features are matched using $k$-nearest 
neighbors.  For any given feature $f_i$ the two most similar neighbors 
are returned, and we calculate the ratio between them as proposed in 
\cite{lowe2004sift}.  Any correspondence with a ratio above the 
threshold supplied will be discarded. Finally in the filter stage we 
check that matches are from different images and discard all matches 
that are not symmetric.
%
%\begin{figure*}
%	\makebox[\textwidth][c]{%
%		\begin{subfigure}[t]{0.32\textwidth}
%			\centering
%			\includegraphics[width=\textwidth]{images/MMC_pitts_source}
%			\caption{Source image pair}
%			\label{fig:pitts_source}
%		\end{subfigure}%
%		\enspace %
%		\begin{subfigure}[t]{0.32\textwidth}
%			\centering
%			\includegraphics[width=\textwidth]{images/MMC_pitts_keypoints}
%			\caption{Feature points}
%			\label{fig:pitts_keypoints}
%		\end{subfigure}%
%		\enspace %add desired spacing between images, e. g. ~, \quad, 
%		%\qquad (or a blank line to force the subfigure onto a new line)
%		\begin{subfigure}[t]{0.32\textwidth}
%			\centering
%			\includegraphics[width=\textwidth]{images/mirror_match_off}
%			\caption{\emph{SIFT}}
%			\label{fig:unique}
%		\end{subfigure}%
%	}
%	\makebox[\textwidth][c]{%
%		\begin{subfigure}[t]{0.32\textwidth}
%			\centering
%			\includegraphics[width=\textwidth]{images/mirror_match_with_pruned}
%			\caption{\emph{MM} intermediate result}
%			\label{fig:within}
%		\end{subfigure}%
%		\enspace %add desired spacing between images, e. g. ~, \quad, 
%		%\qquad (or a blank line to force the subfigure onto a new line)
%		\begin{subfigure}[t]{0.32\textwidth}
%			\centering
%			\includegraphics[width=\textwidth]{images/mirror_match}
%			\caption{\emph{MM} final result}
%			\label{fig:without}
%		\end{subfigure}%
%		\enspace%
%		\begin{subfigure}[t]{0.32\textwidth}
%			\centering
%			\includegraphics[width=\textwidth]{images/MMC_partition}
%			\caption{\emph{MMC} Partition Example}
%			\label{fig:pitts_partition}
%		\end{subfigure}%
%	}%
%	\caption{Illustration of feature matching with \emph{MM} and \emph{MMC}. Dots represent feature points; green/red lines indicate %correct/incorrect matches, respectively; black lines represent edges in the feature graph.  
%(c) Result of \emph{SIFT} matching the two images.% 
%  (d) All matches found by \emph{MM}, including matches between points in the same image. 
%	(e) Final \emph{MM} result with the intra-image matches removed. 
%	(f) Example of a partition of feature points after clustering. This partition 
%includes similar feature points around the windows of a building and the patterns of a shirt.}%
%	\label{fig:comparemirror}%
%\end{figure*}%


Figure~\ref{fig:comparemirror} illustrates the benefits of \emph{MM} 
using an example image pair from the Gallagher dataset 
\cite{gallagher2008}.
With \emph{SIFT} (Figure~\ref{fig:unique}), many incorrect matches occur 
in the fence towards the bottom of the image.
When we match all feature points together, many of these incorrect 
matches are eliminated, because points in the fence match with other 
points in the fence in the same image (Figures~\ref{fig:within} and
\ref{fig:without}).


\subsubsection{Mirror Match with Clustering (\emph{MMC})}
%
In contrast to \emph{MM}, \emph{MMC} diverges from traditional 
non-geometric feature matching by clustering feature points by 
similarity. This process yields partitions of fairly similar feature 
points that we can match using the same approach as \emph{MM}.  
Algorithm~\ref{alg-mmc} shows the pseudocode implementation of \emph{MMC}.

Before we introduce the implementation details we will go over the 
problem of graph clustering and how it relates to feature matching.

Given a set of feature points from two images, $im_1$ and $im_2$: $F_k = 
\{k_i, k_j$ for $k_i \in im_1, k_j \in im_2\}$ as well as a matching 
function $M(k_i, k_j) \rightarrow \mathbb{R}$ that takes two feature 
points in an image and returns their matching score, we can define a 
matrix $A$ where each element $A_ij = M(k_i, k_j)$. A can be interpreted 
as the \emph{adjecency matrix} of the fully connected graph where each 
vertex corresponds to a keypoint and the edge between two vertices has a 
weight equal to the distance between the two corresponding keypoints.

This representation reduces the problem of partitioning the keypoints 
into groups to that of graph clustering or community structure depending 
on the context. In the literature there are various ways of clustering a 
graph according to different measures of what constitutes an optimal 
partitioning. Traditionally the most used clustering algorithms have 
been K-means and spectral clustering, but in recent years a host of new 
algorithms have been proposed based on both Newman's concept of graph 
modularity\footnote{Introduced in \cite{girvan2002}, discussed in 
\cite{brandes2007} and used in \cite{blondel2008} as well as others} as 
well as information theoretical measures\footnote{See for example 
\cite{rosvall2008}} and the Potts spin model from physics\footnote{Used 
in \cite{ronhovde2009}} just to mention a few approaches. Many of the 
new algorithms differ from K-means clustering and Spectral clustering 
in that they do not require the number of expected to clusters to be 
specified beforehand\footnote{Among the aforementioned methods, this is 
true for \cite{blondel2008} and \cite{rosvall2008}}.  Furthermore, on 
tests done using randomly generated graphs with a known partitioning 
\cite{blondel2008}, \cite{rosvall2008} and \cite{ronhovde2009} perform 
markedly better than spectral clustering and 
K-means\cite{lancichinetti2009}.

The performance of clustering algorithms is a complicated issue, since 
an optimal clustering given the same graph can vary depending on the 
application. Spectral clustering for example will usually return a 
partitioning where each partition is roughly equal in size\footnote{As 
mentioned in \cite{von2007}} while the Louvain 
clustering\cite{blondel2008} might return partitions of very uneven 
size, even if the modularity measurement has been shown to penalize very 
small clusters\cite{brandes2007}. Both behaviours can be beneficial 
depending on the application, but when clustering feature points, 
maintaining clusters of an even size usually means that some clusters 
will be '\emph{catch-all}' clusters where the feature points that do 
not fit anywhere else are grouped together. The necessity of specifying 
the amount of partitions in for example Spectral clustering or Pott's 
model clustering further exacerbates the issue since smaller partitions 
are then combined into one to achieve the right amount of partitions.

%
\begin{algorithm}
\caption{Mirror Match with Clustering (\emph{MMC})}
\label{alg-mmc}
%{\fontsize{10}{10}\selectfont
\begin{algorithmic}
\Require $images$ : set of images, $t \in \mathbb{R}$
\State $M\gets \varnothing$
\State $F\gets \varnothing$
\ForAll{$I_i \in images$} \Comment Gather features
	\State $f_i\gets getFeatures(I_i)$
	\State $F\gets F \cup f_i$
\EndFor
\State $A\gets getAdjacencyMatrix(f_1, f_2,\; \ldots \;, f_n)$
\State $A_{norm}\gets 1 - normalize(A)$
\State $A_{pruned}\gets pruneEdges(A_{norm},\alpha)$
\State $P\gets cluster(A_{pruned})$
\ForAll{$p \in P$} \Comment p is a set of feature points
	\State $M\gets M \cup getMatches(p, t, F)$
\EndFor \\
\Return matches
\end{algorithmic}
%}
\end{algorithm}

\begin{figure}[t]
    \centering
\makebox[\textwidth][c]{%
    \includegraphics[width=1.1\textwidth]{images/MMC_graph}
    \label{fig:graph}
}
    \caption{The partitioned feature graph. Each vertex represents a 
        feature point; lines indicate high similarity between points. A 
        partition is a connected group with the same color. The border 
        color of each node indicates which image it belongs to.  Zooming 
    into a subsection of the graph (right part), the various cluster 
sizes can be seen, ranging from hundreds of feature points to only two 
or three.}
	\label{fig:graph}
\end{figure}

We use the Louvain Method \cite{blondel2008} for clustering feature 
points, since it is relatively fast and performs well 
\cite{lancichinetti2009}, does not require parameters 
\cite{blondel2008}, and does not emphasize partitions of equal size, as 
opposed to spectral clustering or k-means \cite{von2007}, for example.
While the Louvain clustering algorithm does not require any parameters 
in itself, it tends towards clustering all feature points together in 
the same partition if the graph is very connected.  To ensure that the 
graph is well clustered, the adjacency matrix is pruned so that only 
edges above a certain threshold are kept. From empirical analysis, 
retaining the top 2.5\% of edges with the highest similarity seems to 
work well in practice. Figure~\ref{fig:graph} shows the result of 
clustering the feature points as a graph.
%

The partitions group feature points by similarity, which means that 
repetitive structures such as buildings often appear in larger 
partitions, as exemplified in Figure~\ref{fig:pitts_partition}.
%
%\begin{figure}
%	\makebox[0.5\textwidth][c]{%
%		\begin{subfigure}[t]{0.24\textwidth}
%			\centering
%			\includegraphics[width=\textwidth]{images/MMC_pitts_source}
%			\caption{Source image}
%			\label{fig:pitts_source}
%		\end{subfigure}%
%		~ %add desired spacing between images, e. g. ~, \quad, \qquad		  
%		%(or a blank line to force the subfigure onto a new line)
%	}%
%	\\
%	\makebox[0.5\textwidth][c]{
%		%~ %add desired spacing between images, e. g. ~, \quad, \qquad		  
%		%(or a blank line to force the subfigure onto a new line)
%		
%		\begin{subfigure}[t]{0.5\textwidth}
%			\centering
%			\includegraphics[width=\textwidth]{images/MMC_partition}
%			\caption{A Partition Example}
%			\label{fig:pitts_partition}
%		\end{subfigure}%
%	}%
%	\caption{Example of a partition of keypoints in an image pair. The 
%		partition shown contains window corners from a building in the 
%		left image and similar corners on the shirt in the right image.  
%	}
%	\label{fig:compare_mirror}
%\end{figure}
%
%The matching algorithm for \emph{MMC} (algorithm \ref{alg-getmatches}) 
%goes through the partitions one by one and selects matches in the 
%following way: If the partition has no edges going from a feature point 
%in one image to a feature point in another image, the partition is 
%discarded. If we have more than one edge going between images then 
%$getMatches$ will behave as \emph{MM} and make sure that a 
%correspondence is symmetric, that it has a ratio above the desired 
%threshold and that it isn't matching two feature points from the same 
%image. Since feature points are all guaranteed to be fairly similar 
%this means that we can set the ratio threshold much higher than in 
%\emph{MM} and include matches that would normally have been discarded 
%for not being sufficiently unique.

The matching algorithm for \emph{MMC}, \emph{getMatches}, finds matches 
within all partitions with more than two elements using the \emph{MM} 
approach.  However, as can be seen in the example in 
Figure~\ref{fig:cropped_graph}, many of the partitions contain only two 
feature points from different images linked by one edge. In such a case, 
we compare the similarity of the these two feature points with their 
second best match and remove matches where this ratio lies above a 
certain threshold, like in the \emph{SIFT} algorithm. For example in the 
case of Figure~\ref{fig:pitts_partition}, we have feature points from a 
building in one image grouped together with points from a shirt pattern 
in another.  The nearest neighbor method would have returned wrong 
matches, but since we match the partition with \emph{MM}, points in the 
building end up matching other points in the building, and no matches 
are returned.

%\begin{algorithm}
%\caption{Impl. of getMatches (\emph{from MMC algorithm})}
%\label{alg-getmatches}
%{\fontsize{10}{10}\selectfont
%\begin{algorithmic}
%\Require $p$ : set of features, $t\in \mathbb{R}$, $features$ : Set of 
%all features
%\State $matches \gets \varnothing$
%\State $edges \gets \left\{similarity(f_i, f_j) \mid getImg(f_i) \neq 
%	getImg(f_j)$
%\State $\wedge f_i, f_j \in p \right\}$
%\If{$\left\vert edges \right\vert = 1$} \Comment If $\exists$ one edge 
%between images
%	\State $f_i,f_j \gets getFeatures(edges_{inter}, p)$
%	\State $f_m,f_n \gets get2NNs(f_i, features ~ 
%\setminus ~ \left\{f_i\right\})$
%	\State $f_s,f_t \gets get2NNs(f_j, features ~ 
%\setminus ~ \left\{f_j\right\})$
%	\State $ratio_i \gets similarity(f_i, f_n) / similarity(f_i, 
%f_j)$
%	\State $ratio_j \gets similarity(f_j, f_t) / similarity(f_j, 
%f_i)$
%	\If{$ratio_i < t\wedge ratio_j < t$}
%		\State $matches \gets matches \cup (f_i, f_j)$
%	\EndIf
%\ElsIf{$\left\vert edges \right\vert > 1$} \Comment If $\exists$ more 
%than one edge between images
%	\ForAll{$f_i \in p$}
%		\State $f_m,f_n \gets get2NNs(f_i, p \setminus 
%\left\{f_i\right\})$
%		\State $ratio \gets similarity(f_i, f_n) / similarity(f_i, 
%f_m)$
%		\If{$getImg(f_i) \neq getImg(f_m) \wedge ratio < t
%\wedge (f_m, f_i) \not\in matches$}
%			\State $matches \gets matches \cup (f_i, f_m)$
%		\EndIf
%	\EndFor
%\EndIf
%
%\Return matches
%\end{algorithmic}
%}
%\end{algorithm}

\subsection{Experiments}
\label{S:Experiments}
%
To reliably measure the accuracy of a matching method on real images, we 
either need a set of image pairs tied by a homography, or we have to manually count 
the number of inliers. The latter becomes prohibitive for large numbers of (non-trivial) images. 

Mikolajczyk and Schmid  \cite{mikolajczyk2005performance} introduced a set of test images
to compare the performance of feature detectors. The 
set covers different types of image variations, such as lighting change, 
blur, rotation, and viewpoint change. Inspired by this 
dataset (in particular the `Graf' image set) and motivated by 
the need for more image pairs featuring viewpoint changes, we have 
compiled a set of 8 image pairs consisting of subjects taken from two 
different angles. The images are collected from Flickr's database of 
images published under a creative commons 
licence %\footnote{\href{http://creativecommons.org/}{www.creativecommons.org}, 
%a copyleft license permitting redistribution} 
and feature murals, which 
makes it possible to relate points in the image pairs with a homography.  
The images have been cropped to show the same motive and resized to 
$900\times 600$ pixels.  This dataset will be referred to as the 
\emph{Murals} dataset.  Figure~\ref{fig:murals} shows one image from each pair.

\begin{figure}[htb]
%	\makebox[0.5\textwidth][c]{%
%		\begin{subfigure}[t]{0.048\textwidth}
%			\centering
%			\includegraphics[width=\textwidth]{images/pair_example1}
%			\label{fig:fairey1}
%	\end{subfigure}%
%		\enspace %add desired spacing between images, e. g. ~, \quad, 
%		%(or a blank line to force the subfigure onto a new line)
%		\begin{subfigure}[t]{0.048\textwidth}
%			\centering
%			\includegraphics[width=\textwidth]{images/pair_example2}
%			\label{fig:fairey2}
%		\end{subfigure}%
%		\enspace %
%		\begin{subfigure}[t]{0.36\textwidth}
			\centering
			\includegraphics[width=\columnwidth]{images/crop_examples}
%		\end{subfigure}%
%	}%
	\caption{Sample test patches produced from an image pair.}
	\label{fig:fairey}
\end{figure}

\begin{figure*}[t]
	\centering
	\includegraphics[width=\textwidth]{images/murals}
	\caption{Images in the \emph{Murals} test set.}
	\label{fig:murals}
\end{figure*}

\begin{figure}[htb]
	\centering
	\includegraphics[width=\columnwidth]{images/graf12345.jpg}
	\caption{Images 1-5 of the Graf set from \cite{mikolajczyk2005performance}.}
	\label{fig:Graf}
\end{figure}


%However in practice the view point change has gone on to be used the 
%most for later tests given that most of the other test pairs have since 
%become easy to match\footnote{see \cite{wu2011robust} or 
%\cite{delponte2006svd} for examples}.

%Inspired by the graffiti image we have collected a set of image pairs 
%featuring murals of a few different artists\footnote{Including Banksy, 
%Blu and Shepard Fairey among others}. Each pair consist of images of 
%the same motive taken from different angles, often including repetitive 
%patterns and texture. Based on this image set the two algorithms are 
%tested on a series of image patches from each pair. To verify that the 
%algorithms proposed are reliable we need to test that we get good 
%matches when images overlap and that we get no matches when they do 
%not.  This means that it isn't enough just testing against pairs of 
%images that we know match.  We also need to test against pairs that 
%might look like they could match but in fact do not.


%
%
%\subsubsection{Experimental setup}
We compare the \emph{MM} and \emph{MMC} algorithms to 
\emph{SIFT} \cite{lowe2004sift} as well 
as \emph{Isodata} \cite{das2008event}. 
\emph{Isodata} uses geometric constraints, whereas \emph{SIFT} does not.
%, which uses geometric information to improve the matching. 
%The comparison  with \emph{SIFT} serves to illustrate the relative performance of 
%\emph{MM} and \emph{MMC} to a state of the art algorithm without 
%geometric constraints. \emph{Isodata} is included to 
%illustrate the performance of an algorithm relying on geometric 
%constraints faced with image pairs that might not have any overlap.  
The 
comparison was done using the \emph{Murals} dataset (Figure~\ref{fig:murals}), the 
\emph{Graf} set (Figure~\ref{fig:Graf}) from \cite{mikolajczyk2005performance}, and two 
images %\footnote{100\_1942.jpg and 100\_1941.jpg} 
from the Gallagher dataset \cite{gallagher2008} (Figure~\ref{fig:comparemirror}).

Test sets were generated from the image pairs by cropping square patches of
$250\!\times\!250$ pixels with a random vertical and horizontal offset.  
Given a source image pair, we produce 100 pairs of patches, which might or might not overlap.  
This ensures that patch pairs with no overlap still retain a general similarity to each 
other, while patches that do overlap often only share a small 
part of their area. Figure~\ref{fig:fairey} shows an example of 
possible pairs of test image patches produced from a source image pair.  
Producing $n$ such pairs allows us to test not just how well the 
matching algorithm performs on a variety of overlaps but also how many 
false positives we get on similar images that do not overlap at 
all.\footnote{~The set of source images and homographies as well as the 
script to generate the cropped test sets based on them will be made 
available online, together with the exact test sets used in this paper 
upon acceptance.}
%\href{https://github.com/arnfred/Murals}{www.github.com/arnfred/Murals}}.  
In practice the amount of overlap between pairs in a test set will 
depend on the overlap and viewpoint change in the source image pair.  To 
give a rough idea, Table~\ref{table:overlap} 
shows the overlap of patch pairs created from images 1 and 3 of the 
\emph{Graf} image set from \cite{mikolajczyk2005performance}.

\begin{table}[htb]
\caption{Overlap in the set of 100 patch pairs created from two images of the \emph{Graf} image set (Figure~\ref{fig:Graf}).}
\label{table:overlap}
	\centering
%	\small
\begin{tabular}{r*{3}{r}}
\hline
	Amount of overlap: & 0\% & $< 50$\% & $> 50$\%  \\
	\noalign{\smallskip}
	%
	Number of patch pairs: & 21 & 54 & 25 \\
	\hline
\end{tabular}
\end{table}


Given a potential match between two pixels $p_1$ and 
$p_2$, $m = \left(p_1, p_2\right)$, and a homography $H$ relating the two images $I_1$ and $I_2$, we 
can calculate if $m$ is an inlier by checking if the two points satisfy the following criteria:
\begin{equation*}
\left\vert H p_1 - p_2 \right\vert + \left\vert H^{-1}p_2 - p_1 \right\vert < d_{\max}
\end{equation*}
That is, the distance between $p_1$ translated to $I_2$ and $p_2$ 
\emph{plus} the distance between $p_2$ translated to $I_1$ should be 
less than a certain threshold (we use $d_{\max}=5$ pixels here).


\subsection{Results}
\label{S:Results}

Figure~\ref{fig:result_graf} shows the results for 100 patch pairs 
generated from images 1 and 3 of the \emph{Graf} image set (cf.~Figure~\ref{fig:Graf}). The plot 
compares the accuracy of \emph{SIFT}, \emph{MM}, \emph{MMC}, and 
\emph{Isodata} as a function of the number of matches produced (which is achieved by varying thresholds over a certain range). The results show that \emph{MM} and \emph{MMC} consistently outperform \emph{SIFT}; \emph{MMC} generally lies 2-3 percentage points above \emph{MM} when both are performing at optimal accuracy. 
Although \emph{Isodata} exhibits a good performance on strict thresholds (small number of matches), that quickly diminishes when more matches are desired.


\begin{figure}[htb]
%	\makebox[0.5\textwidth][c]{%
%		\begin{subfigure}[t]{.13\textwidth}
%			\centering
%			\includegraphics[width=\textwidth]{images/graf}
%		\end{subfigure}%
%		~ %add desired spacing between images, e. g. ~, \quad, \qquad		  
		%(or a blank line to force the subfigure onto a new line)
%		\begin{subfigure}[t]{.27\textwidth}
			\centering
			\includegraphics[width=0.6\columnwidth]{images/result_graf}
			%\caption{Performance on Scharf}
%		\end{subfigure}%
%	}%
	\caption{Accuracy for image pair 1\&3 from the \emph{Graf} set. The plot 
		shows the result of 100 patch pairs generated from the source 
		images shown to the left. The number of matches is the total 
		number of matches for all 100 patch pairs.}
	\label{fig:result_graf}
\end{figure}

To validate whether these results 
generalize to other images, we tested the four algorithms on the 
\emph{Murals} dataset as well as the \emph{Graf} pair tested above.  
In total 900 different patch pairs were generated from 9 
source image pairs.  The results are shown in Figure 
\ref{fig:result_accumulated}. 

\begin{figure}[htb]
	\centering
	\includegraphics[width=\columnwidth]{images/result_accumulated}
	\caption{Results for 900 patch pairs extracted from the \emph{Murals} dataset and the image pair 1\&3 from the \emph{Graf} set.  The x-axis shows the accumulated returned matches for all pairs.}
	\label{fig:result_accumulated}
\end{figure}

To further investigate the impact of viewpoint changes, we tested the 
algorithms on the \emph{Graf} image set (Figure~\ref{fig:Graf}), which 
contains 5 images of the same mural taken with gradually increasing 
viewpoint changes.  The first images are almost identical, while the 
last are taken from very different angles. The results from   \emph{MMC} 
and \emph{SIFT} as shown in Figure~\ref{fig:result_viewpoint}, 
confirming that \emph{MMC} is generally superior to \emph{SIFT} across 
viewpoint changes.
The performance of \emph{MM} (not shown in the plot) is similar to 
\emph{MMC}.

\begin{figure}[htb]
	\centering
	\includegraphics[width=0.45\textwidth]{images/result_viewpoint}
	\caption{Results for viewpoint changes using the \emph{Graf} set from 
		\cite{mikolajczyk2005performance}.  S: img1\&2; M: img1\&3; L: img1\&4; XL: img1\&5.}
	\label{fig:result_viewpoint}
\end{figure}


Finally, for an example of a real life use case, Figure~\ref{fig:result_pitts} 
shows the results on 100 patch pairs generated 
from a typical holiday photo shot (Figure~\ref{fig:pitts_source}) featuring occlusion and a slight viewpoint 
change from the Gallagher dataset \cite{gallagher2008}.  The performance is comparable to the murals, despite the lack of a simple homographic mapping between the images.


\begin{figure}[htb]
%	\makebox[0.5\textwidth][c]{%
%		\begin{subfigure}[t]{.15\textwidth}
%			\centering
%			\includegraphics[width=\textwidth]{images/pitts}
%		\end{subfigure}%
		~%add desired spacing between images, e. g. ~, \quad, \qquad
		%(or a blank line to force the subfigure onto a new line)
%		\begin{subfigure}[t]{.27\textwidth}
			\centering
			\includegraphics[width=0.6\columnwidth]{images/result_pitts}
			%\caption{Performance on Scharf}
%		\end{subfigure}%
%	}%
	\caption{Results for the image pair in Figure~\ref{fig:pitts_source}.}
	\label{fig:result_pitts}
\end{figure}


In terms of computational complexity, \emph{SIFT}, \emph{MM}, and \emph{Isodata} can be 
implemented in $O(n\log n)$, where $n$ is the total number of feature 
points.  Our current \emph{MMC} implementation has a complexity of $O(n^2)$ due to the 
construction of a similarity matrix of the feature points. However, it is 
possible to approximate this in $O(n\log n)$ using search trees.  

In terms of speed, Table~\ref{table:running_times} shows the 
running time of the four algorithms over 100 image pairs of $250\!\times\!250$ pixels. 
These numbers should be taken with a grain of salt, given that 
much of the code behind \emph{MMC} and \emph{Isodata} is implemented in 
Python, whereas \emph{MM} and \emph{SIFT} make use of OpenCV to execute 
computationally intensive operations in C++, which makes them much 
faster. 

\begin{table}[htb]
\caption{Running times as tested on a Intel\textregistered\ Core\texttrademark\ i5-3550 CPU @ 
3.30~GHz with 8~GB memory.}
\label{table:running_times}
	\centering
%	\small
\begin{tabular}{r*{4}{c}}
\hline
	Algorithm: & \emph{SIFT} & \emph{MM} & \emph{MMC} & \emph{Isodata} 
	\\
	\noalign{\smallskip} 
	%
	Running time: & 20.94s & 18.23s & 883.99s & 555.33s \\
	\hline
\end{tabular}
\end{table}
%

\section{Applications}

\subsection{Panorama Recognition and Alignment}
One of the oldest practical problems approached in computer vision is 
the automatic stitching of several source images into a bigger image, 
such as panoramas and composite satellite photos\footnote{A brief 
overview of the history of image stitching can be found in Szeliski's 
book: Computer Vision: Algorithms and Applications \cite{szeliski2010}}.  
As part of the process of stitching together images, the individual 
images must be aligned and often transformed in perspective. Earlier 
methods relied on minimizing pixel dissimilarities in overlapping images 
while more recent methods have used local feature points to estimate the 
correct image alignment. Using local feature points carry the additional 
advantage that it is feasible to automatically recognize where each 
source image belong in the final panorama.

\begin{figure}[h]
	\begin{subfigure}[t]{0.8\textwidth}
		\centering
		\includegraphics[width=\textwidth]{images/pano_narrow}
        \label{fig:pano_images}
		\caption{Source images}
    \end{subfigure}%
	\\
	\centering
	\begin{subfigure}{0.4\textwidth}
		\includegraphics[width=\textwidth]{images/panorama-autostitch}
        \label{fig:pano_autostitch}
		\caption{Panorama by Autostitch}
    \end{subfigure}%
	~%add desired spacing between images, e. g. ~, \quad, \qquad
	%(or a blank line to force the subfigure onto a new line)
	\begin{subfigure}{0.4\textwidth}
		\includegraphics[width=\textwidth]{images/panorama-MMC}
		\caption{Panorama by MMC}
		\label{fig:pano_MMC}
	\end{subfigure}%
    \label{fig:pano_example}
	\caption{An example of a difficult case for panorama recognition and 
		alignment.  In a) the source images used to generate the 
		panorama are displayed.\ b) shows the result of the Autostitch 
		program from \cite{brown2007automatic} which fails to combine 
		all images, while c) demonstrates the result of the simple 
		panorama stitcher
	using the proposed MMC algorithm. Here the two left images are 
correctly linked}
\end{figure}

In \cite{brown2007automatic}, Brown and Lowe demonstrate how a panoramic 
image can be assembled by collecting the feature points of all source 
images and matching them to obtain a set of inter image matches.  By 
using \emph{RANSAC}\footnote{RANdom SAmple Consensus, an iterative 
    algorithm to estimate parameters from noisy data introduced in 
Fischler and Bolles in 1981 \cite{fischler1981ransac}} to find matches 
deemed as inliers between image pairs, they are able to recognize image 
neighbors and align them to construct the final panorama.

This process hinges on the effectiveness of the matching algorithm used 
to match the feature points. Not only is it important that true pairs 
are accurately matched, but since we are matching points in image pairs 
that might not be adjacent in the final panorama, we also need to make 
sure that we consistently reject false positives, i.e.\ proposed matches 
that link feature points which don't correspond.

To demonstrate the usefulness of \emph{MMC} applied to panorama 
recognition and alignment we construct a simple panorama stitcher taking
as input a set of $n$ source images $\left\{I_0, \ldots, I_n\right\}$ 
and returns as output a panoramic image stitched together from the 
source images. Based on the matches found by applying \emph{MMC} to $I$, 
the images are combined in an order corresponding to how many matches 
connect them, as done by Brown and Lowe \cite{brown2007automatic}.

Brown and Lowe make use of bundle adjustment\footnote{Bundle adjustment 
provides a way to globally optimize the accuracy of the image alignment} 
and a lot of image enhancements such as exposure adjustment and edge 
blurring to provide a seamless panorama. While these additions improve 
the end product, they don't influence the performance of panorama 
alignment and recognition and haven't been included in the simple 
comparison algorithm.

Figure~\ref{fig:pano_example} shows an example where the added accuracy 
of MMC enables us to correctly recognitize and align source images that 
fail to be combined by Autostitch, a program using the algorithm 
proposed by Brown and Lowe \cite{brown2007automatic}. In this particular
case the matching algorithm used in Autostitch fails to find sufficient 
matches between two images pairs to correctly position them and 
consequently doesn't produce a panorama containing all images as a 
result.

This example illustrates how an improved matching algorithm can be 
applied to panorama recognition and alignment to allow for panoramas 
created with images that have little overlap.
% Maybe find example of images with identical features that would be 
% hard to match?

\subsection{Near Duplicate Detection}
Both with regards to corporate intellectual property as well as consumer 
photo albums, being able to automatically find near duplicates of images 
provides useful across several scenarios. A company might be interested 
in finding images that are derived from their intellectual property, 
while consumers taking vacation photos might be interested in grouping 
duplicate images to allow for easier photo organization.

Local features are often used to group similar images, either by looking
at a histogram of descriptors \cite{wu2009bundling} or by looking at how
well feature points match between images \cite{zhao2009scale},
\cite{chu2010consumer}, \cite{vas2013cluster}. In the latter case 
finding near duplicates means that we will be matching image pairs that 
might or might not contain any actual matches. In this case we would 
benefit from a reliable matching algorithm that minimizes false 
positives, which is a characteristic of both \emph{MM} and \emph{MMC}.

The PhotoCluster method introduced by Vonikakis et al.  
\cite{vas2013cluster} shows the best clustering performance on the 
California-nd dataset \cite{jinda2012california} which contains a set of
annotated vacation images similar to a typical photo album in a consumer
product. PhotoCluster works by grouping images in several steps using 
first image metadata and global features to obtain a set of proposed 
clusters. Then local features are used to find the best matching images 
in these proposed clusters yielding the final groups of near duplicate 
images. To show the viability of \emph{MMC} in the application of near 
duplicated detection, we modify the PhotoCluster method to use 
\emph{MMC} for matching images instead of \emph{Ratio} which was 
previously used. Due to the time consumption of \emph{MMC}, all images 
where resized to to 10\% before being compared. Outside of that, the 
experiments were performed exactly as documented in 
\cite{vas2013cluster}.

\begin{table}[htb]
\caption{Results from Near Duplicate Detection at 10\% scale}
\label{table:ndd}
	\centering
%	\small
\begin{tabular}{r*{2}{r}}
\hline
    Method: & Ratio & MMC   \\
	\noalign{\smallskip}
	%
    F1 score: & 0.4654 & 0.5459 \\
	\hline
\end{tabular}
\end{table}

The results of the comparison can be seen in Table~\ref{table:nnd} where
\emph{MMC} improves performance by 8.05\% over the original framework 
using \emph{Ratio} to match images.


% About near duplicates mention how we can't use ransac to find inliers 
% since we can't necessarily construct a homography between two images

There are two important steps to image stitching which i- Describe in 
general why better matching improves the results and speed on a broad 
range of different computer vision problems
 - Elaborate on why the two examples where chosen (are there any 
 particular reasons?)
 - Near duplicate detection
 - Panorama application

\section{Summary}
\label{S:Summary}

We have addressed the problem of matching feature points without using 
geometrical constraints, proposing \emph{Mirror Match 
(MM)} and \emph{Mirror Match with Clustering (MMC)}.  The two algorithms 
share the common idea that feature points should have better 
matches in another image than in the image they came from to be 
considered good matches.  \emph{MMC} further improves on this idea by 
using the structure of the similarity graph of the feature points. 

The algorithms show promising results when tested on the \emph{Murals} data 
set. %, where pairs of the same object seen from different angles are %cropped to have different degrees of overlap ranging from full to non at all. The results on 900 patch pairs show that 
\emph{MM} and \emph{MMC} 
generally outperform existing matching algorithms \emph{SIFT} and \emph{Isodata}, and \emph{MMC} 
outperforms \emph{MM}. We show that this result generalizes to 
variations in viewpoint change as well as more realistic photos featuring occlusions. 
% by comparing \emph{MMC} to \emph{SIFT} over a set of image pairs with an increasing magnitude of perspective difference. 
%We go on to apply the algorithms to a real life image case 
%featuring occlusion and a slight viewpoint change and show that the 
%performance of \emph{MM} and \emph{MMC} is consistent with the results 
%on \emph{Murals}.  

Given the versatility of the proposed algorithms, we are planning to apply them to problems that require high 
reliability faced with images that might not match, such as near 
duplicate detection or face recognition.
%

\bibliographystyle{IEEEtran}
\bibliography{bibliography}
\end{document}
