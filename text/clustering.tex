\documentclass[12pt,journal]{IEEEtran}
%\documentclass{article}
\usepackage{footnote}
\usepackage[font={small}]{caption}
\usepackage{sidecap}
\usepackage{graphicx}
\usepackage{cite}
\usepackage{hyperref}
\usepackage[stable]{footmisc}
\usepackage{caption}
\usepackage{adjustbox}
\usepackage{subcaption}
\usepackage{algpseudocode}
\usepackage{algorithm}
\usepackage{amsmath}
\usepackage{amssymb}

\begin{document}

\title{Reliable feature point matching without the use of geometric 
constraints}
%\author{Jonas Arnfred and what to put here exactly?}

\maketitle
%
\begin{abstract}
Many algorithms have been proposed to solve the problem of matching 
feature points in two or more images using geometric assumptions to 
increase the robustness of the matching. However very little work 
addresses the case where these assumptions might not hold true. In 
particular few methods address the problem of reliable matching in cases 
where we don't know if two images have any corresponding areas or 
objects. In this paper we propose two algorithms for matching feature 
points without the use of geometric constraints. The first makes use of 
the fact that any match between two images should be better than all 
possible matches within the image itself. The second algorithm extends 
this idea by using community structure in the similarity graph of 
feature points to reliably find correspondences. To evaluate the 
algorithms experimentally we introduce a set of 8 image pairs all 
containing viewport changes and a simple method to generate a large 
amount of test cases based on these 8 pairs. The experimental results 
show that the proposed algorithm, overall, is superior to traditional 
approaches in finding correct correspondences.
\end{abstract}
%
\section{Introduction}
%
When matching feature points between two or more images we are often 
faced with the problem of correctly identifying the actual 
correspondences among many possible pairings. Several methods have been 
proposed in the literature to solve this problem. Many approaches look 
at the geometric configuration of the feature points and match them 
according to assumptions made about the geometric relationship between 
the images matched. These assumptions are then used to create 
constraints used to evaluate the matches such as angular constraints 
\cite{kim2008efficient}, epipolar constraints \cite{torr2000mlesac}, 
\cite{chum2005matching} and pairwise constraints \cite{choi2009robust}, 
\cite{leordeanu2005spectral}.
%
%When matching feature points between two or more images we are often 
%faced with the problem of correctly identifying the actual 
%correspondences among many possible pairings. Several methods have been 
%proposed in the literature to solve this problem. In particular many 
%approaches look at the geometric configuration of the feature points 
%and match them according to assumptions made about the geometric 
%relationship between the images matched. A simple example would be to 
%only consider matches that aren't deviating too much with respect to 
%the average angle and distancen as considered by 
%\cite{kim2008efficient}.  This performs well in situations where no 
%camera rotation occurs between the two images, but fails when this 
%assumption isn't met. Various scenarios have been proposed to improve 
%on this simple assumption such as epipolar constraints 
%(\cite{torr2000mlesac}, \cite{chum2005matching}) and pairwise 
%constraints (\cite{choi2009robust}, \cite{leordeanu2005spectral}). The 
%Epipolar constraint carries the assumption that the two images matched 
%are related by an affine transformation. That is, there is no relative 
%movement of objects in between images and either the viewpoint is fixed 
%or the image resides entirely on a plane. In practice this assumption 
%largely holds true when all objects we are interested in matching are 
%roughly the same distance from the camera and when we expect to match 
%objects that are consistently positioned across images.  Pairwise 
%constraints provide a more robust approach to the same problem by 
%looking at a set of proposed correspondences and defining a pairwise 
%error between any two matches for example based on the assumption that 
%two neighboring correspondences will usually have similar angles and 
%distances. We can then convert the problem to an optimization problem 
%and return a set of correspondences that minimizes this error such as 
%proposed in \cite{choi2009robust} and \cite{leordeanu2005spectral}.  
%This approach provides more robustness in cases where assumptions that 
%are violated globally still hold on a local scale.
%
Alternatively we can pick out different areas in each image and pair 
areas when correspondence pairs are mainly found going from one area to 
another. This allows for the filtering of all correspondences that do 
not fall within paired areas. Examples include \cite{das2008event} and 
\cite{wu2011robust}.
%
%proposes clustering feature points by using their geometric position 
%and exclude correspondences that are geometrically deviant. A more 
%sophisticated approach is introduced in \cite{wu2011robust} where the 
%areas are created by using the MSER feature detector to find areas of 
%interest in the images. These areas can be defined as an ellipse with a 
%certain radius around the interest points. The feature points that fall 
%within this ellipse are then matched according to epipolar constraints.  
%
In practice however, there are many situations where using the geometry 
of the image to filter correspondences is not possible, such as object 
recognition where adjecent objects in one photo might be separated in 
another. Another example is images that do not overlap where algorithms 
might still find matches adhering to the imposed geometric constraints.
In addition methods using geometric constraints all require a set of 
correspondences to begin with. If this set of correspondences is 
narrowed down to a smaller set with a higher ratio of correct matches 
the result of the geometric matching will be both faster and more 
accurate.  Finally some use cases might require a performance that can't 
be achieved by a more complex geometric method where simple non 
geometric methods might be able to provide sufficient matching accuracy 
with a smaller performance penalty.

There are a relatively small number of algorithms proposed to solve the 
matching problem without involving geometric constraints. Traditionally 
the feature points of two images have been matched by comparing every 
feature point of one image with all feature points of the other and 
finding the best matches based on the similarity of the descriptors.  
With the introduction of the SIFT features \cite{lowe2004sift}, Lowe 
proposes an alternative measure where the uniqueness of a given match is 
found by looking at the two nearest neighbors of each feature point and 
calculating a match score by the ratio of similarities. Ranking the 
scores by their uniqueness and picking the $n$ best produces a set of 
correspondences that are distinctly matched across the two images. This 
method will be referred to as \emph{SIFT} in this paper.

In turn the two methods proposed in this paper are inspired by a simple 
but novel idea. If we have two images and a given feature point in the 
first image is better matched with other feature points from the 
\emph{same} image than points in the other image, then any matches of 
this feature point to points in the other image is deemed unreliable and 
discarded.  This approach carries no implicit assumptions about the 
geometric consistency of matches and can as such easily be extended with 
other geometric solutions when appropriate.

%Based on this idea the two proposed methods find reliable matches as 
%follows:
%\begin{itemize}
%\item[]{\emph{Mirror Match (MM)}: Match features using the gold standard 
%		algorithm\cite[p. 114]{multipleView} ranked by similarity and 
%		thresheld by uniqueness\cite{lowe2004sift}.  However instead of 
%		matching features from one image with features in another, we 
%	match every feature with all other features of the two images 
%combined. Only matches from one image to the other are returned.}
%\item[]{\emph{Mirror Match with Clustering (MMC)}: Take the combined set 
%		of feature points from both images and cluster these points 
%		according to their descriptors. Given a resulting partition of 
%		points, no matches are returned if it contains only feature 
%	points from one image. If the partition contains points from both 
%images, \emph{Mirror Match} is used to find the best matches within the 
%partition.}
%\end{itemize}
%%
%Matching feature points against the entire set of points from both 
%images ensures that the distinctiveness of a returned correspondence is 
%higher. In almost all cases\footnote{Exceptions would include cases 
%where we want to find all particular points in a pattern and other use 
%cases where the correspondence isn't assumed to be unique}, a good 
%match between two images is unambiguous in the sense that there are no 
%other equally good potential matches to the same point.  This is the 
%key insight behind the algorithm presented by Lowe in 
%\cite{lowe2004sift}.  However the implication doesn't follow the other 
%way around. In the case that a feature point doesn't have a true 
%correspondence there might still exist point with which the feature 
%point is uniquely matched. The issue is particularly pronounced if we 
%compare two images that don't correspond. For any proposed 
%correspondence it is entirely probable that this correspondence is 
%unique even if it isn't correct. When we match against the feature 
%points of both images this ambiguity is avoided.  When the two images 
%have no overlap or objects in common, chances are that a feature point 
%will match better with another feature point from the same image in 
%which case it is easily discarded.
%
%Often images will contain repetitive patterns that are difficult to 
%match\footnote{In fact this particular problem has been given attention 
%before by for example \cite{fan2011towards}} because the feature 
%descriptors covering these patterns will be similar. If we remove points 
%that aren't deemed sufficiently unique like in \emph{MM} this means that 
%these points will often be discarded even if they are correctly matched.
%\emph{MMC} makes it possible to look at groups of similar feature points 
%one at a time and within each group find the best matches. This is done 
%by taking the set of feature points from both images and cluster them by 
%their similarity. In some cases the clustering will end up grouping 
%feature points of only one image together which can then easily be 
%discarded in the matching process.  In other cases partitions will 
%contain similar feature points from both images that can then be matched 
%using \emph{MM} but with much lower thresholds.
%
\section{Matching Methods}
\subsection{Mirror Match (\emph{MM})}
%
The central idea behind \emph{MM} is to match features of $n$ images by 
taking every feature from all $n$ images and matching it against every 
other feature from the same set. We can then discard the correspondences 
that match two points within the same image. In algorithm \ref{alg-mm} 
the implementation of \emph{MM} is shown.
%
\begin{algorithm}
\caption{Mirror Match Algorithm (\emph{MM})}
\label{alg-mm}
{\fontsize{10}{10}\selectfont
\begin{algorithmic}
\Require $images$ : set of images, $t$ : float $\in \mathbb{R}$
\State $matches_{init}\gets \varnothing$
\State $matches_{final}\gets \varnothing$
\State $features\gets \varnothing$
\ForAll{$I_i \in images$} \Comment Gather Stage
	\State $features\gets features \cup getFeatures(I_i)$
\EndFor
\ForAll{$f_i \in features$} \Comment Match Stage
	\State $f_m,f_n \gets get2NNs(f_i, features ~ \backslash ~ 
	\left\{f_i\right\})$
	\State $ratio \gets similarity(f_i, f_n) / similarity(f_i, f_m)$
	\If{$ratio < t$}
		\State $matches_{init} \gets \left(f_i, f_m\right)$
	\EndIf
\EndFor
\ForAll{$\left(f_i, f_j \right) \in matches_{init}$} \Comment Filter 
Stage
\If{$\left(f_j, f_i \right) \in matches_{init} \wedge getImg(f_i) \neq 
getImg(f_j) \wedge \left(f_j, f_i\right) \not\in matches_{final}$}
		\State $matches_{final} \gets (f_i, f_j)$
	\EndIf
\EndFor \\
\Return $matches_{final}$
\end{algorithmic}
}
\end{algorithm}
%
In the acquisition state we gather all features in the set of images.  
These features are then matched in the match stage using K-Nearest 
Neighbors.  For any given feature $f_i$ the two most similar neighbors 
are returned and we calculate the ratio between them as as proposed in 
\cite{lowe2004sift}.  Any correspondence with a ratio above the 
threshold supplied will be discarded. Finally in the filter stage we 
check that matches are from different images and discard all matches 
that are not symmetric.
%
\begin{figure*}
	\makebox[\textwidth][c]{%
		\begin{subfigure}[t]{0.32\textwidth}
			\centering
			\includegraphics[width=\textwidth]{images/MMC_pitts_source}
			\caption{Source image}
			\label{fig:pitts_source}
		\end{subfigure}%
		\enspace %
		\begin{subfigure}[t]{0.32\textwidth}
			\centering
			\includegraphics[width=\textwidth]{images/MMC_pitts_keypoints}
			\caption{Keypoints Displayed}
			\label{fig:pitts_keypoints}
		\end{subfigure}%
		\enspace %add desired spacing between images, e. g. ~, \quad, 
		%\qquad (or a blank line to force the subfigure onto a new line)
		\begin{subfigure}[t]{0.32\textwidth}
			\centering
			\includegraphics[width=\textwidth]{images/mirror_match_off}
			\caption{\emph{SIFT}}
			\label{fig:unique}
		\end{subfigure}%
	}
	\makebox[\textwidth][c]{%
		\begin{subfigure}[t]{0.32\textwidth}
			\centering
			\includegraphics[width=\textwidth]{images/mirror_match}
			\caption{\emph{MM}}
			\label{fig:without}
		\end{subfigure}%
		\enspace%
		\begin{subfigure}[t]{0.32\textwidth}
			\centering
			\includegraphics[width=\textwidth]{images/mirror_match_with_pruned}
			\caption{\emph{MM} with intra image matches}
			\label{fig:within}
		\end{subfigure}%
		\enspace %add desired spacing between images, e. g. ~, \quad, 
		%\qquad (or a blank line to force the subfigure onto a new line)
		\begin{subfigure}[t]{0.32\textwidth}
			\centering
			\includegraphics[width=\textwidth]{images/MMC_partition}
			\caption{\emph{MMC} Partition Example}
			\label{fig:pitts_partition}
		\end{subfigure}%
	}%
	\caption{Illustration of matches filtered by \emph{MM}. For each 
	correct match found between the two images, a green line is shown.  
Incorrect matches are marked with a red line. Figure \ref{fig:within} 
shows the correspondences found by mirror match, but including all 
matches that are found within the same image. }%
	\label{fig:comparemirror}%
\end{figure*}%

In figure \ref{fig:comparemirror} an example of the result of \emph{MM} 
is illustrated. Notice how the by the bottom of the image admits 
correspondences that can conveniently be removed as done in sub figure 
\ref{fig:without} where only the actual correspondences returned by the 
algorithm are shown.

\subsection{Mirror Match with Clustering (\emph{MMC})}
%
As opposed to \emph{MM}, \emph{MMC} diverges from traditional 
non-geometric feature matching by clustering the feature points by 
similarity. This process yields partitions of fairly similar feature 
points that we can match using the same approach as \emph{MM}. 
%
%Before we introduce the implementation details we will go over the 
%problem of graph clustering and how it relates to feature matching.
%
%\subsubsection{Graph Clustering}
%
%Given a set of feature points from two images, $im_1$ and $im_2$: $F_k = 
%\{k_i, k_j$ for $k_i \in im_1, k_j \in im_2\}$ as well as a matching 
%function $M(k_i, k_j) \rightarrow \mathbb{R}$ that takes two feature 
%points in an image and returns their matching score, we can define a 
%matrix $A$ where each element $A_ij = M(k_i, k_j)$. A can be interpreted 
%as the \emph{adjecency matrix} of the fully connected graph where each 
%vertex corresponds to a keypoint and the edge between two vertices has a 
%weight equal to the distance between the two corresponding keypoints.
%
%This representation reduces the problem of partitioning the keypoints 
%into groups to that of graph clustering or community structure depending 
%on the context. In the literature there are various ways of clustering a 
%graph according to different measures of what constitutes an optimal 
%partitioning. Traditionally the most used clustering algorithms have 
%been K-means and spectral clustering, but in recent years a host of new 
%algorithms have been proposed based on both Newman's concept of graph 
%modularity\footnote{Introduced in \cite{girvan2002}, discussed in 
%\cite{brandes2007} and used in \cite{blondel2008} as well as others} as 
%well as information theoretical measures\footnote{See for example 
%\cite{rosvall2008}} and the Potts spin model from physics\footnote{Used 
%in \cite{ronhovde2009}} just to mention a few approaches. Many of the 
%new algorithms differ from K-means clustering and Spectral clustering in 
%that they don't require the number of expected to clusters to be 
%specified beforehand\footnote{Among the aforementioned methods, this is 
%true for \cite{blondel2008} and \cite{rosvall2008}}.  Furthermore, on 
%tests done using randomly generated graphs with a known partitioning 
%\cite{blondel2008}, \cite{rosvall2008} and \cite{ronhovde2009} perform 
%markedly better than spectral clustering and 
%K-means\cite{lancichinetti2009}.
%
%The performance of clustering algorithms is a complicated issue, since 
%an optimal clustering given the same graph can vary depending on the 
%application. Spectral clustering for example will usually return a 
%partitioning where each partition is roughly equal in size\footnote{As 
%mentioned in \cite{von2007}} while the Louvain 
%clustering\cite{blondel2008} might return partitions of very uneven 
%size, even if the modularity measurement has been shown to penalize very 
%small clusters\cite{brandes2007}. Both behaviours can be beneficial 
%depending on the application, but when clustering feature points, 
%maintaining clusters of an even size usually means that some clusters 
%will be '\emph{catch-all}' clusters where the feature points that don't 
%fit anywhere else are grouped together. The necessity of specifying the 
%amount of partitions in for example Spectral clustering or Pott's model 
%clustering further exacerbates the issue since smaller partitions are 
%then combined into one to achieve the right amount of partitions.

We use the Louvain Method\cite{blondel2008} for clustering feature 
points since it's relatively fast and performs 
well\cite{lancichinetti2009}, doesn't require 
parameters\cite{blondel2008} and doesn't emphasize partitions of equal 
sizes as opposed to for example spectral clustering and 
k-means\cite{von2007}.
%
\begin{algorithm}
\caption{Mirror Match with Clustering Algorithm (\emph{MMC})}
\label{alg-mmc}
{\fontsize{10}{10}\selectfont
\begin{algorithmic}
\Require $images$ : set of images, $t \in \mathbb{R}$
\State $M\gets \varnothing$
\State $F\gets \varnothing$
\ForAll{$I_i \in images$} \Comment Gather features
	\State $f_i\gets getFeatures(I_i)$
	\State $F\gets F \cup f_i$
\EndFor
\State $A\gets getAdjecencyMatrix(f_1, f_2,\; \ldots \;, f_n)$
\State $A_{norm}\gets 1 - normalize(A)$
\State $A_{pruned}\gets pruneEdges(A_{norm},\alpha)$
\State $P\gets cluster(A_{pruned})$
\ForAll{$p \in P$} \Comment p is a set of feature points
	\State $M\gets M \cup getMatches(p, t, F)$
\EndFor \\
\Return matches
\end{algorithmic}
}
\end{algorithm}

While the louvain clustering algorithm doesn't require any parameters in 
itself, it tends towards clustering all feature points together in the 
same partition if the graph is very connected.  To ensure that the graph 
is well clustered, the adjacency matrix is pruned so only edges above a 
certain threshold is kept. From empirical analysis keeping around 2.5\% 
of edges seems to work well. Figure \ref{fig:graph} shows the result of 
clustering the feature points displayed as a graph.
%
\begin{SCfigure*}
	\makebox[0.7\textwidth][c]{%
		\begin{subfigure}[t]{0.28\textwidth}
			\centering
			\includegraphics[width=\textwidth]{images/MMC_graph_full}
			\caption{Full Graph}
			\label{fig:full_graph}
		\end{subfigure}%
		~ %add desired spacing between images, e. g. ~, \quad, \qquad		  
		%(or a blank line to force the subfigure onto a new line)
		\begin{subfigure}[t]{0.28\textwidth}
			\centering
			\includegraphics[width=\textwidth]{images/MMC_graph_cropped}
			\caption{Cropped Section of Graph}
			\label{fig:cropped_graph}
		\end{subfigure}%
	}%
	\caption{The partitioned feature graph. Each vertex represents a 
		feature point while an edge represent a high similarity between 
		points. A partition is a connected group marked by a color.  Due 
		to a limited amount of colors some disconnected partitions have 
		been assigned the same color. The edge color of each node 
		signifies which image it belongs to. In the detailed crop to the 
		right the various cluster sizes can be seen, ranging from 
	hundreds of feature points to only two or three.}
	\label{fig:graph}
\end{SCfigure*}

The partitions group feature points by similarity which means that 
repetitive structures such as buildings often feature in larger 
partitions as exemplified in figure \ref{fig:pitts_partition}.
%
%\begin{figure}
%	\makebox[0.5\textwidth][c]{%
%		\begin{subfigure}[t]{0.24\textwidth}
%			\centering
%			\includegraphics[width=\textwidth]{images/MMC_pitts_source}
%			\caption{Source image}
%			\label{fig:pitts_source}
%		\end{subfigure}%
%		~ %add desired spacing between images, e. g. ~, \quad, \qquad		  
%		%(or a blank line to force the subfigure onto a new line)
%	}%
%	\\
%	\makebox[0.5\textwidth][c]{
%		%~ %add desired spacing between images, e. g. ~, \quad, \qquad		  
%		%(or a blank line to force the subfigure onto a new line)
%		
%		\begin{subfigure}[t]{0.5\textwidth}
%			\centering
%			\includegraphics[width=\textwidth]{images/MMC_partition}
%			\caption{A Partition Example}
%			\label{fig:pitts_partition}
%		\end{subfigure}%
%	}%
%	\caption{Example of a partition of keypoints in an image pair. The 
%		partition shown contains window corners from a building in the 
%		left image and similar corners on the shirt in the right image.  
%	}
%	\label{fig:compare_mirror}
%\end{figure}
%
%The matching algorithm for \emph{MMC} (algorithm \ref{alg-getmatches}) 
%goes through the partitions one by one and selects matches in the 
%following way: If the partition has no edges going from a feature point 
%in one image to a feature point in another image, the partition is 
%discarded. If we have more than one edge going between images then 
%$getMatches$ will behave as \emph{MM} and make sure that a 
%correspondence is symmetric, that it has a ratio above the desired 
%threshold and that it isn't matching two feature points from the same 
%image. Since feature points are all guaranteed to be fairly similar 
%this means that we can set the ratio threshold much higher than in 
%\emph{MM} and include matches that would normally have been discarded 
%for not being sufficiently unique.

The matching for \emph{MMC} \emph{getMatches} finds matches within all 
partitions with more than two elements as done in \emph{MM}. However as 
can be seen in the example in figure \ref{fig:cropped_graph} many of the 
partitions contain only two feature points from different images linked 
by one edge. In this case we compare the similarity of this match to the 
next best match across all partitions and filter the matches based on 
this ratio like in \emph{SIFT}.
%\begin{algorithm}
%\caption{Impl. of getMatches (\emph{from MMC algorithm})}
%\label{alg-getmatches}
%\begin{algorithmic}
%\Require $p$ : set of features, $t\in \mathbb{R}$, $features$ : Set of 
%all features
%\State $matches \gets \varnothing$
%\State $edges \gets \left\{getSimilarity(f_i, f_j) \mid getImg(f_i) \neq 
%getImg(f_j) \wedge f_i, f_j \in p \right\}$
%\If{$\left\vert edges \right\vert = 1$} \Comment If $\exists$ one edge 
%between images
%	\State $f_i,f_j \gets getInterImageFeatures(edges_{inter}, p)$
%	\State $f_m,f_n \gets getTwoNearestNeighbors(f_i, features ~ 
%\backslash ~ \left\{f_i\right\})$
%	\State $f_s,f_t \gets getTwoNearestNeighbors(f_j, features ~ 
%\backslash ~ \left\{f_j\right\})$
%	\State $ratio_i \gets getSimilarity(f_i, f_n) / getSimilarity(f_i, 
%f_j)$
%	\State $ratio_j \gets getSimilarity(f_j, f_t) / getSimilarity(f_j, 
%f_i)$
%	\If{$ratio_i < t\wedge ratio_j < t$}
%		\State $matches \gets matches \cup (f_i, f_j)$
%	\EndIf
%\ElsIf{$\left\vert edges \right\vert > 1$} \Comment If $\exists$ more 
%than one edge between images
%	\ForAll{$f_i \in p$}
%		\State $f_m,f_n \gets getTwoNearestNeighbors(f_i, p ~ \backslash 
%~ \left\{f_i\right\})$
%		\State $ratio \gets getSimilarity(f_i, f_n) / getSimilarity(f_i, 
%f_m)$
%		\If{$getImg(f_i) \neq getImg(f_m) \wedge ratio < t
%\wedge (f_m, f_i) \not\in matches$}
%			\State $matches \gets matches \cup (f_i, f_m)$
%		\EndIf
%	\EndFor
%\EndIf
%
%\Return matches
%\end{algorithmic}
%\end{algorithm}
%
\section{Experiments}
\label{experiment}
%
To reliably measure the accuracy of a matching method on real images we 
either need a set of image pairs tied by a homography or manually count 
the number of inliers. The latter becomes unfeasible the moment we 
attempt to test a non-trivial set of images. 

In \cite{mikolajczyk2005performance} Mikolajczyk and Schmid introduces a 
set of images to compare the performance of feature detectors. The test 
set covers different types of image variance such as different lighting, 
blur, rotation as well as viewpoint change. Inspired by this 
dataset\footnote{In particular by the 'Graf' image set} and motivated by 
the need for more image pairs featuring viewport changes, we have 
compiled a set of $8$ image pairs consisting of the same subject taken 
from two different angles. The images are collected from Flickr's 
database of images published under a creative commons 
licence\footnote{\href{http://creativecommons.org/}{www.creativecommons.org}, 
a copyleft license permitting redistribution} and feature murals which 
makes it possible to relate points in the image pairs with a homography.  
The images have been cropped to feature the same motive and resized to 
$900$px by $600$px. This dataset will be referred to as the 
\emph{Murals} dataset in this paper. The images can be seen in figure 
\ref{fig:murals}.

\begin{figure*}
	\centering
	\includegraphics[width=\textwidth]{images/murals}
	\caption{Images in the mural test set}
	\label{fig:murals}
\end{figure*}

%However in practice the view point change has gone on to be used the 
%most for later tests given that most of the other test pairs have since 
%become easy to match\footnote{see \cite{wu2011robust} or 
%\cite{delponte2006svd} for examples}.

%Inspired by the graffiti image we have collected a set of image pairs 
%featuring murals of a few different artists\footnote{Including Banksy, 
%Blu and Shepard Fairey among others}. Each pair consist of images of 
%the same motive taken from different angles, often including repetitive 
%patterns and texture. Based on this image set the two algorithms are 
%tested on a series of image patches from each pair. To verify that the 
%algorithms proposed are reliable we need to test that we get good 
%matches when images overlap and that we get no matches when they don't.  
%This means that it isn't enough just testing against pairs of images 
%that we know match.  We also need to test against pairs that might look 
%like they could match but in fact don't.


%
\begin{figure}
	\makebox[0.5\textwidth][c]{%
		\begin{subfigure}[t]{0.048\textwidth}
			\centering
			\includegraphics[width=\textwidth]{images/pair_example1}
			\label{fig:fairey1}
		\end{subfigure}%
		\enspace %add desired spacing between images, e. g. ~, \quad, 
		%(or a blank line to force the subfigure onto a new line)
		\begin{subfigure}[t]{0.048\textwidth}
			\centering
			\includegraphics[width=\textwidth]{images/pair_example2}
			\label{fig:fairey2}
		\end{subfigure}%
		\enspace %
		\begin{subfigure}[t]{0.36\textwidth}
			\centering
			\includegraphics[width=\textwidth]{images/crop_examples}
		\end{subfigure}%
	}%
	\caption{Example of test set produced by a source pair of images}
	\label{fig:fairey}
\end{figure}
%
%\subsection{Experimental setup}
The \emph{MM} and \emph{MMC} algorithms have been tested against 
\emph{SIFT}, the algorithm Lowe proposed in \cite{lowe2004sift} as well 
as the \emph{Isodata} matching algorithm proposed in \cite{das2008event} 
which uses geometric information to improve the matching. The comparison 
has been done using the \emph{Murals} dataset, the \emph{Graf} set from 
\cite{mikolajczyk2005performance} and two images\footnote{100\_1942.jpg 
and 100\_1941.jpg} from \cite{gallagher2008} illustrated in figure 
\ref{fig:pitts_partition}.

Test sets have been generated from the image pairs by cropping out 
$250$px by $250$px patches with a random vertical and horizontal offset.  
Given a source image pair we produce $100$ pairs of patches where the 
two patches in any pair might or might not overlap.  This ensures that 
the patch pairs with no overlap still retain a basic similarity to each 
other, while the patches that do overlap often only overlap on a small 
part of their surface. Figure \ref{fig:fairey} shows an example of 
possible pairs of test images produced from a source image pair.  
Producing $n$ such pairs allows us to test not just how well the 
matching algorithm performs on a variety of overlap but also how many 
false positives we get on similar images that don't overlap at 
all\footnote{The set of source images and homographies as well as the 
	script to generate the cropped test sets based on them have been 
made available online together with the exact test sets used in this 
paper on 
\href{https://github.com/arnfred/Murals}{www.github.com/arnfred/Murals}}.

To judge whether a possible match ($p_1, p_2$) should be counted as an 
inlier given a homography $H$ relating two images $I_1$ and $I_2$ we 
test if $p_1$ and $p_2$ satisfies the following criterium:

$$\left\vert Hp_1 - p_2 \right\vert + \left\vert H^{-1}p_2 - p_1 
\right\vert < 5$$
%
\section{Results}
\label{results}

\begin{figure}
	\makebox[0.5\textwidth][c]{%
		\begin{subfigure}[t]{.13\textwidth}
			\centering
			\includegraphics[width=\textwidth]{images/graf}
		\end{subfigure}%
		~ %add desired spacing between images, e. g. ~, \quad, \qquad		  
		%(or a blank line to force the subfigure onto a new line)
		\begin{subfigure}[t]{.27\textwidth}
			\centering
			\includegraphics[width=\textwidth]{images/result_graf}
			%\caption{Performance on Scharf}
		\end{subfigure}%
	}%
	\caption{Accuracy on the \emph{Graf} set from 
		\cite{mikolajczyk2005performance} using img1 and img3. The plot 
		shows the result of $100$ image pairs generated from the source 
		images shown to the left. The number of matches is the total 
		number of matches for all $100$ image pairs.}
	\label{fig:result_graf}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[width=0.45\textwidth]{images/result_accumulated}
	\caption{Results on the \emph{Murals} dataset and the pair of img1 
		and img3 from the \emph{Graf} image set from 	
		\cite{mikolajczyk2005performance}. For each of the 9 source 
		image pairs, 100 test pairs have been created.  The x-axis 
	illustrates the accumulated returned matches for all pairs.}
	\label{fig:result_accumulated}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[width=0.45\textwidth]{images/result_viewport}
	\caption{Results on viewport changes using the \emph{Graf} set from 
		\cite{mikolajczyk2005performance} as image pair sources. Img 1 
		to 6 in the \emph{Graph} set are images of the same subject but 
		with gradually increasing view port change. Img1 and 2 are 
		almost identical while img1 and 6 are taken from very different 
		angles. S is a testst of $100$ crops from img1 and img2. M is 
	likewise but based on img1 and img3.  L is img1 and img4 and XL is 
img1 and img5.  To decrease clutter \emph{MM} is not shown, but it 
performs alike to \emph{MMC}}
	\label{fig:result_viewport}
\end{figure}

Figure \ref{fig:result_graf} shows the results for 100 image pairs 
generated from img1 and img3 of the \emph{Graf} image set. The plot 
illustrates the results of \emph{SIFT}, \emph{MM}, \emph{MMC} and 
\emph{Isodata} as thresholds are varied over a range. \emph{Isodata} 
performs well with strict thresholds, but when we require more matches 
\emph{MM} and \emph{MMC} show superior results. To see if this results 
generalizes over more image sets, we tested the four algorithms on the 
\emph{Murals} dataset as well as the \emph{Graf} pair tested in fig.  
\ref{fig:result_graf}. In total 900 image pairs were generated from 9 
source pairs generating the plot shown in figure 
\ref{fig:result_accumulated} displaying the accumulated amount of 
matches on the x-axis. To verify that this performance is independent of 
the magnitude of view port change, we tested \emph{MMC} and \emph{SIFT} 
on the \emph{Graf} image set as shown in figure 
\ref{fig:result_viewport}. The figure confirms that \emph{MMC} is 
generally superior across view port changes.

For an example of a real life use case figure \ref{fig:result_pitts} 
shows the results on potentially overlapping image pairs generated from 
a typical holiday scene with partial overlap and slight view port 
change.

In terms of performance, table \ref{table:running_times} shows the 
running time of the four algorithms over $100$ image pairs of $250$px by 
$250$px. These numbers should be interpreted with the knowledge that 
much of the code behind \emph{MMC} and \emph{Isodata} is implemented in 
python while \emph{MM} and \emph{SIFT} makes use of opencv to execute 
computationally intensive operations in C++ which renders it much 
faster. While \emph{SIFT}, \emph{MM} and \emph{Isodata} can be 
implemented in $O(nlogn)$ where $n$ is the total amount of feature 
points, \emph{MMC} currently has a complexity of $O(n^2)$ due to the 
construction of a similarity matrix of the feature points. It is however 
possible to approximate this in $O(nlogn)$ using search trees, something 
that could be pursued in future work.
%
\begin{savenotes}
\begin{table}
	\centering
	\small
\begin{tabular}{l*{4}{c}}
	Algorithm: & \emph{SIFT} & \emph{MM} & \emph{MMC} & \emph{Isodata} 
	\\
	\noalign{\smallskip} 
	%
	Running time: & 20.94s & 18.23s & 883.99s & 555.33s \\
\end{tabular}
\caption{Running times as tested on a Intel(R) Core(TM) i5-3550 CPU @ 
3.30GHz with 8Gb memory}
\label{table:running_times}
\end{table}
\end{savenotes}
%

\begin{figure}
	\makebox[0.5\textwidth][c]{%
		\begin{subfigure}[t]{.15\textwidth}
			\centering
			\includegraphics[width=\textwidth]{images/pitts}
		\end{subfigure}%
		~ %add desired spacing between images, e. g. ~, \quad, \qquad		  
		%(or a blank line to force the subfigure onto a new line)
		\begin{subfigure}[t]{.27\textwidth}
			\centering
			\includegraphics[width=\textwidth]{images/result_pitts}
			%\caption{Performance on Scharf}
		\end{subfigure}%
	}%
	\caption{Accuracy on an image pair from the Gallagher dataset from 
		\cite{gallagher2008} using cropped versions of 100\_1941 and 
		100\_1942. The plot shows the result of $100$ image pairs 
		generated from the source images shown to the left.  The number 
	of matches is the total number of matches for all $100$ image 
pairs.}
	\label{fig:result_pitts}
\end{figure}

\section{Summary}
We have addressed the problem of matching feature points without using 
geometrical constraints and proposed two algorithms \emph{Mirror Match 
(MM)} and \emph{Mirror Match with Clustering (MMC)}. The two algorithms 
share the same common idea that feature points should have better 
matches in another image than in the image they came from to be 
considered good matches and \emph{MMC} further improves on this idea by 
using the structure of the similarity graph of the feature points. We 
also address how to test the algorithms by constructing the 
\emph{Murals} dataset consisting of $8$ source image pairs and a way to 
generate testsets based on these pairs.  The proposed approach shows 
promising results on both the \emph{Murals} dataset as well as a real 
life example from the Gallagher dataset and the \emph{Graf} image set, 
surpassing even a method using geometrical constraints when matching 
image pairs that might not overlap.
%
\bibliographystyle{IEEEtran}
\bibliography{bibliography}
\end{document}

