\documentclass{article}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage[stable]{footmisc}
\usepackage{caption}
\usepackage{adjustbox}
\usepackage{subcaption}
\usepackage{algpseudocode}
\usepackage{algorithm}
\usepackage{amsmath}
\usepackage{amssymb}

\begin{document}

\title{Clustering feature points}
\author{Jonas Arnfred}

\maketitle

\begin{abstract}
% TODO!
\end{abstract}

\section{Introduction}

Since the introduction of feature points, several methods for matching 
them across images have been proposed in order to maximize the amount of 
correct matches. In this part of the project I introduce two methods to 
reliably match feature points. The word 'reliable' covers that matches 
only are returned if they are judged as sound. That is, matches should 
only be returned if there are objects or scenes that appear in both 
images.

When matching feature points between two images we are often faced with 
a dilemma between making the feature descriptor more discriminative to 
make sure only correct matches are made, and making it less 
discriminative to increase the robustness of the descriptor over 
different changes such as illumination, perspective and image quality.  
Any feature type aiming for robustness will have cases where it isn't 
possible to generate reliable matches if we only look at the pairwise 
correspondence of the descriptors. 

To get around this limitation several methods have been proposed in the 
literature. One of the most fruitful approaches have been to look at the 
geometric configuration of the feature points and match them with 
respect to assumptions concerning the variance between images. For 
example an angular and distance constraint between matches as considered 
by \cite{kim2008efficient} performs well in situations where no camera 
rotation occurs between the two images but will likely fail in other 
cases. Various scenarios have been proposed to improve on this simple 
assumption such as epipolar constraints (\cite{torr2000mlesac}, 
\cite{chum2005matching}) and pairwise constraints 
(\cite{choi2009robust}, \cite{leordeanu2005spectral}). The Epipolar 
constraint carries the assumption that the two images matched are 
related by an affine transformation. That is, there is no relative 
movement of objects in between images and either the viewpoint is fixed 
or the image resides entirely on a plane. In practice this assumption 
largely holds true when all objects we are interested in matching are 
roughly the same distance from the camera and when we don't expect to 
match objects that aren't consistently positioned across images.  
Pairwise constraints provide a more robust approach to this problem by 
looking at a set of proposed correspondences and defining a pairwise 
error between any two matches usually based on the assumption that two 
neighboring correspondences will usually have similar angles and 
distances. We can then convert the problem to an optimization problem 
and return a set of correspondences that minimizes this error such as 
proposed in \cite{choi2009robust} and \cite{leordeanu2005spectral}.  
This approach provides more robustness because assumptions that might 
not be true globally often still holds on a local level.

Another approach proposed in the literature is to pick out different 
zones in each image and find a pairing of zones where feature points are 
only matched within the same zone. \cite{das2008event} proposes 
clustering the feature points using their geometric position and 
matching only feature points between groups that have a certain amount 
of matchings between them. A more sophisticated approach is introduced 
in \cite{wu2011robust} where the zones are created by surrounding MSER 
feature points by an ellipse and grouping the SIFT or SURF feature 
points that fall within the ellipse together. These points can then be 
matched according to epipolar constraints.

In practice there are many situations where using the geometry of the 
image to filter correspondences is not possible. This situation most 
often arise when the assumptions made by a geometric method turns out 
not to hold in a particular use case. This could matchings between 
images where the content has been scrambled or with so little 
consistency that even the geometric assumptions break down even on a 
local level. In addition the geometric methods all require a set of 
correspondences to begin with. If this set of correspondences is 
narrowed down to a smaller set with a higher ratio of inliers the result 
of the geometric matching will be both faster and more accurate. Finally 
some use cases might require a performance that can't be achieved by a 
more complex geometric method where simple non geometric methods might 
be able to provide additional matching accuracy with a smaller 
performance penalty. This approach is inspired by \cite{wu2009bundling} 
where bundling of feature points was used to enhance the search results 
in large scale partial-duplicate web image search.

There are a relatively small number of algorithms proposed to solve the 
matching problem without involving geometric constraints. Traditionally 
the feature points of two images have been matched by comparing the 
every feature point of one image with all feature points of the other 
and finding the best matches based on the similarity of the descriptors.  
With the introduction of the SIFT features \cite{lowe2004sift}, Lowe 
proposes an alternative measure where the uniqueness of a given match is 
found by looking at the two nearest neighbors of each feature point and 
calculating a match score by the ratio of similarities. By ranking the 
scores by their uniqueness and picking the $n$ best we get a set of 
correspondences that are distinctly matched across the two images. In 
the book Multiple View Geometry \cite[p.  114]{multipleView}, the gold 
standard algorithm is introduced which ranks correspondences by 
similarity and further filters them by discarding matches that aren't 
symmetric, i.e. that for every feature point $f_i$ matching $f_j$ we 
also have that $f_j$ matches $f_i$.

In turn the two methods proposed in this report are inspired by a simple 
but novel idea. If we have two images and a given feature point in the 
first image is better matched with other feature points from the 
\emph{same} image than points in the other image, then any matches of 
this feature point to points in the other image is deemed unreliable and 
discarded.  This approach carries no implicit assumptions about the 
geometric consistency of matches and can as such easily be extended with 
other geometric solutions when appropriate.

Based on this idea the two proposed methods find reliable matches as 
follows:
\begin{itemize}
\item{\emph{Mirror Match (MM)}: Match features using the gold standard 
algorithm\cite[p. 114]{multipleView} ranked by similarity and thresheld 
by uniqueness\cite{lowe2004sift}. However instead of matching features 
from one image with features in another, we match every feature with all 
other features of the two images combined. Only matches from one image 
to the other are returned.}
\item{\emph{Mirror Match with Clustering (MMC)}: Take the combined set 
of feature points from both images and cluster these points according to 
their descriptors. Given a resulting partition of points, no matches are 
returned if it contains only feature points from one image. If the 
partition contains points from both images, \emph{Mirror Match} is used 
to find the best matches within the partition.}
\end{itemize}

Matching feature points against the entire set of points from both 
images ensures that the distinctiveness of a returned correspondence is 
higher. In almost all cases\footnote{Exceptions would include cases 
where we want to find all particular points in a pattern and other use 
cases where the correspondence isn't assumed to be unique}, a good match 
between two images is unambiguous in the sense that there are no other 
equally (or almost equally) good potential matches to the same point.  
This is the key insight behind the algorithm presented by Lowe in 
\cite{lowe2004sift}. However the implication doesn't follow the other 
way around. In the case that a feature point don't have any actual 
correspondence in the other image, there is no guarantee that this 
feature point might not still be uniquely matched to a feature point in 
the other image. The issue is particularly pronounced if we compare two 
images that don't correspond. For any proposed correspondence it is 
entirely probable that this correspondence is unique even if it isn't 
correct. With Mirror Match this ambiguity is avoided by incorporating 
the feature points of both images when a match is made. When the two 
images have nothing to do with each other, chances are that a feature 
point will match better with another feature point from the same image 
in which case it is easily discarded.

Often images will contain repetitive patterns that are difficult to 
match\footnote{In fact this particular problem has been given attention 
before by for example \cite{fan2011towards}} because the feature points 
covering these patterns will look very similar. If we threshold by 
uniqueness like in Mirror Match this means that these points will often 
be discarded even if they might have good correspondences. To solve this 
problem the enhanced Mirror Match with Clustering makes it possible to 
look at groups of similar feature points one at a time and within each 
group finding the best matches. This is done by taking the set of 
feature points from both images and clustering. The resulting partitions 
will each contain feature points that are similar to each other. In some 
cases the clustering will end up grouping feature points of only one 
image together which can then easily be discarded in the matching 
process. In other cases partitions will contain feature points from both 
images that can then be matched using \emph{MM} but with lower 
thresholds.

The report is organized as follows. In section \ref{algorithms} I will 
describe the two algorithms. Section \ref{experiment} will cover the 
experimental set up and introduce the image set that is used in testing.  
In section \ref{results} I will go through the results and conclude.

\section{Algorithms}
\label{algorithms}

To discuss the implementation of \emph{MM} and \emph{MMC} a few notes on 
notation will be helpful. BLAH BLAH!

\subsection{Mirror Match (\emph{MM})}

The central idea behind \emph{MM} is to match features of $n$ images by 
taking every feature from all $n$ images and matching it against every 
other feature from the same set. We can then discard the correspondences 
that match two points within the same image. In algorithm \ref{alg-mm} 
the actual implementation of \emph{MM} is shown.

\begin{algorithm}
\caption{Mirror Match Algorithm (\emph{MM})}
\label{alg-mm}
\begin{algorithmic}
\Require $images$ : set of images, $threshold$ : float $\in \mathbb{R}$
\State $matches_{init}\gets \varnothing$
\State $matches_{final}\gets \varnothing$
\State $features\gets \varnothing$
\ForAll{$I_i \in images$} \Comment Gather features of all images
	\State $features\gets features \cup getFeatures(I_i)$
\EndFor
\ForAll{$f_i \in features$} \Comment Get best match for all features
	\State $f_m,f_n \gets getTwoNearestNeighbors(f_i, features ~ 
\backslash ~ \left\{f_i\right\})$
	\State $ratio \gets getSimilarity(f_i, f_n) / getSimilarity(f_i, 
f_m)$
	\If{$ratio < threshold$}
		\State $matches_{init}\gets \left(f_i, f_m\right)$
	\EndIf
\EndFor
\ForAll{$\left(f_i, f_j \right) \in matches_{init}$} \Comment Filter 
matches
\If{$\left(f_j, f_i \right) \in matches_{init} \wedge getImg(f_i) \neq 
getImg(f_j)$}
		\State $matches_{final} \gets (f_i, f_j)$
		\State $matches_{init} \gets matches_{init} \ (f_j, f_i)$
	\EndIf
\EndFor \\
\Return $matches_{final}$
\end{algorithmic}
\end{algorithm}

This algorithm passes over three states: An acquisition state where 
feature points are gathered, a matching state where the initial set of 
correspondences are found and a filtering state where correspondences 
within the same image are removed. In the acquisition state the function 
\emph{getFeatures($I_i$)} returns a set of feature points given an 
image.  In practice the feature used for the experiments have been 
SIFT\cite{lowe2004sift}, but there aren't any reason why other features 
such as SURF\cite{bay2006surf} or BRIEF\cite{calonder2010brief} couldn't 
be used just as well. The matching state uses K-Nearest Neighbors to 
return the two closest neighbors in the set of features for any given 
feature $f_i$ and calculates the ratio between the correspondences as 
proposed in \cite{lowe2004sift}.  Any correspondence with a ratio below 
the threshold supplied will be discarded. Finally in the filter the 
function \emph{getImg($f_i$)} returns the parent image of the feature 
$f_i$ and discards both correspondences that aren't symmetric as well as 
those that match two points in the same image.

\begin{figure}
	\makebox[\textwidth][c]{%
		\begin{subfigure}[t]{0.45\textwidth}
			\centering
			\includegraphics[width=\textwidth]{images/mirror_match_off}
			\caption{Baseline Result}
			\label{fig:unique}
		\end{subfigure}%
		%~ %add desired spacing between images, e. g. ~, \quad, \qquad		  
		%(or a blank line to force the subfigure onto a new line)
		\begin{subfigure}[t]{0.45\textwidth}
			\centering
			\includegraphics[width=\textwidth]{images/mirror_match_with_pruned}
			\caption{\emph{MM} with intra image matches}
			\label{fig:within}
		\end{subfigure}%
		%~ %add desired spacing between images, e. g. ~, \quad, \qquad
		  %(or a blank line to force the subfigure onto a new line)
		\begin{subfigure}[t]{0.45\textwidth}
			\centering
			\includegraphics[width=\textwidth]{images/mirror_match}
			\caption{\emph{MM}}
			\label{fig:without}
		\end{subfigure}%
	}%
	\label{fig:compare_mirror}
	\caption{Illustration of matches filtered by \emph{MM}}
\end{figure}

Figure \ref{fig:compare_mirror} shows an example of the performance of 
\emph{MM}. In sub figure \ref{fig:unique} the result of a normal 
matching of two images is shown. The two images appear side by side and 
for each correspondence between them, a line has been drawn from one 
image to the other. The color of the line indicates if the 
correspondence is accurate. Sub figure \ref{fig:within} shows the 
correspondences found by mirror match using the same threshold before 
the matches within the same image has been filtered out. In particular 
the fence by the bottom of the image admits correspondences that can 
conveniently be removed as done in sub figure \ref{fig:without} where 
only the actual correspondences returned by the algorithm are shown.

\subsection{Mirror Match with Clustering (\emph{MMC})}

As opposed to \emph{MM}, \emph{MMC} diverges from traditional 
non-geometric feature matching by clustering the feature points by 
similarity. This process yields partitions of fairly similar feature 
points that we can match using the same approach as \emph{MM}. Before I 
introduce the implementation details I will go over the problem of graph 
clustering and how it relates to feature matching.

\subsubsection{Graph Clustering}

Given a set of feature points from two images, $im_1$ and $im_2$: $F_k = 
\{k_i, k_j$ for $k_i \in im_1, k_j \in im_2\}$ as well as a matching 
function $M(k_i, k_j) \rightarrow \mathbb{R}$ that takes two feature 
points in an image and return their matching score, we can define a 
matrix $A$ where each element $A_ij = M(k_i, k_j)$. A can be interpreted 
as the \emph{adjecency matrix} of the fully connected graph where each 
vertex corresponds to a keypoint and the edge between two vertices has a 
weight equal to the distance between the two corresponding keypoints.

This representation reduces the problem of partitioning the keypoints 
into groups to that of graph clustering or community structure depending 
on the context. In the literature there are various ways of clustering a 
graph according to different measures of what constitutes an optimal 
partitioning. Traditionally the most used clustering algorithms have 
been K-means and spectral clustering, but in recent years a host of new 
algorithms have been proposed based on both Newman's concept of graph 
modularity\footnote{Introduced in \cite{girvan2002}, discussed in 
\cite{brandes2007} and used in \cite{blondel2008} as well as others} as 
well as information theoretical measures\footnote{See for example 
\cite{rosvall2008}} and the Potts spin model from physics\footnote{Used 
in \cite{ronhovde2009}} just to mention a few approaches. Many of the 
new algorithms differ from K-means clustering and Spectral clustering in 
that they don't require the number of expected to clusters to be 
specified beforehand\footnote{Among the aforementioned methods, this is 
true for \cite{blondel2008} and \cite{rosvall2008}}.  Furthermore, on 
tests done using randomly generated graphs with a known partitioning 
\cite{blondel2008}, \cite{rosvall2008} and \cite{ronhovde2009} perform 
markedly better than spectral clustering and 
K-means\cite{lancichinetti2009}.

The performance of clustering algorithms is a complicated issue, since 
an optimal clustering given the same graph can vary depending on the 
application. Spectral clustering for example will usually return a 
partitioning where each partition is roughly equal in size\footnote{As 
mentioned in \cite{von2007}} while the Louvain 
clustering\cite{blondel2008} might return partitions of very uneven 
size, even if the modularity measurement has been shown to penalize very 
small clusters\cite{brandes2007}. Both behaviours can be beneficial 
depending on the application, but when clustering feature points, 
maintaining clusters of an even size usually means that some clusters 
will be '\emph{catch-all}' clusters where the feature points that don't 
fit anywhere else are grouped together. The necessity of specifying the 
amount of partitions in for example Spectral clustering or Pott's model 
clustering further exacerbates the issue since smaller partitions are 
then combined into one to achieve the right amount of partitions.

Based on these observations I've decided to use Louvain clustering for 
grouping feature points since it's fast, performs well, doesn't require 
parameters and doesn't emphasize partitions of equal sizes.

\subsubsection{Clustering feature points using Louvain clustering}

\begin{algorithm}
\caption{Mirror Match with Clustering Algorithm (\emph{MMC})}
\label{alg-mmc}
\begin{algorithmic}
\Require $images$ : set of images, $threshold \in \mathbb{R}$
\State $matches\gets \varnothing$
\State $features\gets \varnothing$
\ForAll{$I_i \in images$} \Comment Gather features of all images
	\State $f_i\gets getFeatures(I_i)$
	\State $features\gets features \cup f_i$
\EndFor
\State $A\gets getAdjecencyMatrix(f_1, f_2,\; \ldots \;, f_n)$
\State $A_{norm}\gets 1 - normalize(A)$
\Comment Shorter distance is higher weight
\State $A_{pruned}\gets pruneEdges(A_{norm},\alpha)$
\State $Partitions\gets cluster(A_{pruned})$
\ForAll{$p \in Partitions$} \Comment p is a set of feature points
	\State $matches\gets matches \cup getMatches(p, threshold, 
features)$
\EndFor \\
\Return matches
\end{algorithmic}
\end{algorithm}

Unlike the \emph{MM} algorithm the feature points are partitioned before 
the matching stage. While the louvain clustering algorithm doesn't 
require any parameters in itself, it tends towards clustering all 
feature points together in the same partition if the graph is fully 
connected or close. To ensure that the graph is well clustered, the 
adjacency matrix is pruned so only edges above a certain threshold is 
kept. From empirical analysis keeping around 2.5\% of edges seems to 
work well. Figure \ref{fig:graph} shows the result of clustering the 
feature points displayed as a graph where each node correspond to a 
feature point. Here the border of nodes signifies the original image 
while the color of the node is decided by what partition it belongs to.  
Notice that since a limited amount of colors are used disconnected 
subgraphs of the same color can be assumed to belong to separate 
partitions. The sub figure \ref{fig:cropped_graph} shows a detailed 
section of the graph where the interplay between small clusters 
consisting of two or three nodes as well as larger clusters consisting 
of several hundred nodes can be seen.

\begin{figure}
	\makebox[\textwidth][c]{%
		\begin{subfigure}[t]{0.60\textwidth}
			\centering
			\includegraphics[width=\textwidth]{images/MMC_graph_full}
			\caption{Full Graph}
			\label{fig:full_graph}
		\end{subfigure}%
		%~ %add desired spacing between images, e. g. ~, \quad, \qquad		  
		%(or a blank line to force the subfigure onto a new line)
		\begin{subfigure}[t]{0.60\textwidth}
			\centering
			\includegraphics[width=\textwidth]{images/MMC_graph_cropped}
			\caption{Cropped Section of Graph}
			\label{fig:cropped_graph}
		\end{subfigure}%
	}%
	\label{fig:graph}
	\caption{The partitioned feature graph. Every color signifies a 
partition while the edge color of each node signifies which image it 
belongs to}
\end{figure}

The clusters 
\begin{figure}
	\makebox[\textwidth][c]{%
		\begin{subfigure}[t]{0.60\textwidth}
			\centering
			\includegraphics[width=\textwidth]{images/MMC_pitts_source}
			\caption{Source image}
			\label{fig:pitts_source}
		\end{subfigure}%
		%~ %add desired spacing between images, e. g. ~, \quad, \qquad		  
		%(or a blank line to force the subfigure onto a new line)
		\begin{subfigure}[t]{0.60\textwidth}
			\centering
			\includegraphics[width=\textwidth]{images/MMC_pitts_keypoints}
			\caption{Keypoints Displayed}
			\label{fig:pitts_keypoints}
		\end{subfigure}%
	}%
	\\
	\makebox[\textwidth][c]{
		%~ %add desired spacing between images, e. g. ~, \quad, \qquad		  
		%(or a blank line to force the subfigure onto a new line)
		
		\begin{subfigure}[t]{1.16\textwidth}
			\centering
			\includegraphics[width=\textwidth]{images/MMC_partition}
			\caption{A Partition Example}
			\label{fig:pitts_partition}
		\end{subfigure}%
	}%
	\label{fig:compare_mirror}
	\caption{Example of partitioning of keypoints in an image}
\end{figure}


\begin{algorithm}
\caption{Impl. of GetMatches (\emph{from MMC algorithm})}
\label{alg-getmatches}
\begin{algorithmic}
\Require $p$ : set of features, $threshold \in \mathbb{R}$, $features$ : 
Set of all features
\State $matches \gets \varnothing$
\State $edges \gets \left\{getSimilarity(f_i, f_j) \mid getImg(f_i) \neq 
getImg(f_j) \wedge f_i, f_j \in p \right\}$
\If{$\left\vert edges \right\vert = 1$} \Comment If $\exists$ one edge 
between images
	\State $f_i,f_j \gets getInterImageFeatures(edges_{inter}, p)$
	\State $f_m,f_n \gets getTwoNearestNeighbors(f_i, features ~ 
\backslash ~ \left\{f_i\right\})$
	\State $f_s,f_t \gets getTwoNearestNeighbors(f_j, features ~ 
\backslash ~ \left\{f_j\right\})$
	\State $ratio_i \gets getSimilarity(f_i, f_n) / getSimilarity(f_i, 
f_j)$
	\State $ratio_j \gets getSimilarity(f_j, f_t) / getSimilarity(f_j, 
f_i)$
	\If{$ratio_i < threshold \wedge ratio_j < threshold$}
		\State $matches \gets matches \cup (f_i, f_j)$
	\EndIf
\ElsIf{$\left\vert edges \right\vert > 1$} \Comment If $\exists$ more 
than one edge between images
	\ForAll{$f_i \in p$}
		\State $f_m,f_n \gets getTwoNearestNeighbors(f_i, p ~ \backslash 
~ \left\{f_i\right\})$
		\State $ratio \gets getSimilarity(f_i, f_n) / getSimilarity(f_i, 
f_m)$
		\If{$getImg(f_i) \neq getImg(f_m) \wedge ratio < threshold 
\wedge (f_m, f_i) \not\in matches$}
			\State $matches \gets matches \cup (f_i, f_m)$
		\EndIf
	\EndFor
\EndIf

\Return matches
\end{algorithmic}
\end{algorithm}

Algorithm \ref{alg-mmc} shows the basic steps taken to find matches in 
two or more images. 

This algorithm is a simplified version of the proposed method completely 
agnostic of the geometry of the feature points in the picture. To better 
explain the algorithm here is a step by step explication of the inputs 
and functions mentioned:
\begin{itemize}
\item[]{\emph{images}: The images we are matching}
\item[]{\emph{$n$}: The number of weights per row in the adjecency 
matrix.}
\item[]{\emph{getFeatures}: Returns a set of feature points given an 
image. In practice the BRIEF\cite{calonder2010brief} feature point 
detector and descriptor has worked well, but it could easily be replaced 
with any other feature point type.} 
% TODO: include a comparison of SURF, SIFT, etc
\item[]{\emph{getAdjecencyMatrix}: Based on the distance measure used to 
compare the similarity of the feature points a symmetric adjecency 
matrix is returned.}
\item[]{\emph{pruneEdges}: The result of the Louvain clustering depends 
on the density of the graph. To ensure an optimal number of partitions 
we only keep the $n$ highest weights per row and column in the adjecency 
matrix, making sure it's still symmetric afterwards. In practice setting 
$n$ to around four or five yields good results.}
\item[]{\emph{cluster}: Cluster the graph corresponding to the adjecency 
matrix given using the Louvain algorithm in \cite{blondel2008}.}
\item[]{\emph{getPositions}: Given a trait consisting of features in 
several different images, find the positions of traits in each image and 
return them. This could either be done by taking a mean of the feature 
points in an image, or by returning the position of the highest matching 
feature points within the trait. In practice ... TODO}
\end{itemize}

The two algorithms introduced in this report are designed to work with 
feature points such as ,  or similar. While the experimental results 
have all been done with the SIFT descriptor, there aren't any 
theoretical or practical issues with using other types of feature 
points. 

In this report I propose two algorithms for better matching feature 
points without any geometric assumptions about the images matched. The 
two algorithms are complementary in the sense that the first, Mirror 
Match (\emph{MM}) is less complex but performs slightly worse than 
Mirror Match with Clustering (\emph{MMC}). In cases where high 


\section{Experiments and Image Set}
\label{experiment}

\section{Results}
\label{results}
\subsection{Graph Clustering}


\subsubsection{On the subject of features}

TODO: Show examples of the same image with feature points from different 
detectors and explain the difference. Go in to why brief seems to work 
best in practice and superficially explain how brief works compared with 
SIFT. 



\begin{algorithm}
\caption{Cluster-Match Algorithm With Geometry}
\label{alg-geometry}
\begin{algorithmic}
\Require $images$ : set of images, $\alpha$ : float $\in \left[0, 
1\right]$, $\beta$ : float $\in \left[0, 1\right]$
\State $matches\gets \varnothing$
\ForAll{$I_i \in images$} \Comment Gather features of all images
	\State $f_i\gets getFeatures(I_i)$
\EndFor
\State $A\gets getAdjecencyMatrix(f_1, f_2,\; \ldots \;, f_n)$
\State $B\gets getGeomDistanceMatrix(f_1, f_2,\; \ldots \;, f_n)$
\State $M\gets getInterImageMask(f_1, f_2,\; \ldots \;, f_n)$
\State $B_{norm}\gets 1 - normalize(G)$ \State $A_{norm}\gets 1 - 
normalize(A)$
\State $A_{geom}\gets A_{norm}\left[ \neg M\right] + \beta \cdot 
B_{norm}\left[M\right]$
\State $A_{pruned}\gets pruneEdges(A_{geom},\alpha)$
\State $P\gets cluster(A_{pruned})$ 
\ForAll{$p \in P$}
	\State $trait\gets \left\{p \cap f_i \mid p \cap f_i \neq 
\varnothing, f_i \in \left\{f_1, f_2,\; \ldots \;, f_n\right\}\right\}$
	\If{$\left\vert trait \right\vert > 1$}
		\State $matches\gets getPositions(trait)$
		\Comment Position of trait in each image
	\EndIf
\EndFor \\
\Return matches
\end{algorithmic}
\end{algorithm}

While clustered feature points are often geometrically close together, 
there might be cases where several points in the same image are similar 
enough to all be included in one cluster despite their geometrical 
distance.  To solve this problem we can either modify the clustering 
algorithm to take the geometric distances into account like 
\cite{das2008event}.  Alternatively we can modify the weight matrix to 
penalize putting distanced feature points in the same cluster. However 
we only know the geometrical distance between two feature points as long 
as both belong to the same image. One way to approach this problem is to 
replace all the weights of edges between two feature points within the 
same image with their distance. For the case of two images the 
normalized adjecency matrix is defined as follows:
%
$$A_{norm}=
\begin{bmatrix}
w_{1,1}   & w_{1,2}   & \ldots & w_{1,n-1}   & w_{1,n}     \\
w_{2,1}   & w_{2,2}   & \ldots & w_{2,n-1}   & w_{2,n}     \\
\vdots    & \vdots    & \ddots & \vdots      & \vdots      \\
w_{n-1,1} & w_{n-1,2} & \ldots & w_{n-1,n-1} & w_{n-1,n}   \\
w_{n,1}   & w_{n,2}   & \ldots & w_{n,n-1}   & w_{n,n}
\end{bmatrix}=
\begin{bmatrix}
A_{im1} & S       \\
T       & A_{im2} \\
\end{bmatrix}
$$
%
In a similar manner we can define an adjecency matrix based on the 
geometrical distance. Note for example how $d_{1,n}$ can take any value 
as it denotes the geometric distance of feature points in two different 
images and as such can be set to any value.
%
$$B_{norm}=
\begin{bmatrix}
d_{1,1}   & d_{1,2}   & \ldots & d_{1,n-1}   & d_{1,n}     \\
d_{2,1}   & d_{2,2}   & \ldots & d_{2,n-1}   & d_{2,n}     \\
\vdots    & \vdots    & \ddots & \vdots      & \vdots      \\
d_{n-1,1} & d_{n-1,2} & \ldots & d_{n-1,n-1} & d_{n-1,n}   \\
d_{n,1}   & d_{n,2}   & \ldots & d_{n,n-1}   & d_{n,n}
\end{bmatrix}=
\begin{bmatrix}
B_{im1} & R       \\
Q       & B_{im2} \\
\end{bmatrix}
$$
%
Given these two and a weight factor $\beta$ we can construct a new 
weight matrix as follows:
%
$$C=
\begin{bmatrix}
\beta \cdot B_{im1} & S       \\
T       & \beta \cdot B_{im2} \\
\end{bmatrix}
$$
%
Since we prune the matrix afterwards, it's important to choose a weight 
factor that doesn't lead to all edges being either intra image edges or 
intra image edges, since the first would create no clusters across 
images and the latter would mean that the geometrical information would 
be discarded and the bipartite graph constituting of edges between 
feature points in the two images would be used instead.

\bibliographystyle{abbrv}
\bibliography{bibliography}
\end{document}

