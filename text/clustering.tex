\documentclass[conference]{IEEEtran}
%\documentclass{article}
\usepackage{footnote}
%\usepackage[font={small}]{caption}
%\usepackage{sidecap}
\usepackage{graphicx}
\usepackage{cite}
\usepackage{hyperref}
%\usepackage[stable]{footmisc}
%\usepackage{caption}
%\usepackage{adjustbox}
\usepackage{subcaption}
\usepackage{algpseudocode}
\usepackage{algorithm}
\usepackage{amsmath}
\usepackage{amssymb}

\begin{document}

\title{Mirror Match: Reliable Feature Point Matching Without Geometric Constraints}
\author{Anonymous ACPR Submission}

\maketitle
%
\begin{abstract}
Many algorithms have been proposed to solve the problem of matching 
feature points in two or more images using geometric assumptions to 
increase the robustness of the matching. However, very little work 
addresses the case where these assumptions might not hold. In particular 
few methods address the problem of reliable matching in cases where it 
is unknown whether two images have any corresponding areas or objects in 
the first place. 

We propose two algorithms for matching feature points without the use of 
geometric constraints. The first relies on the fact that any match 
between two images should be better than all possible matches within a 
single image. The second algorithm extends this idea by using community 
structure in the similarity graph of feature points to find reliable 
correspondences. To evaluate the algorithms experimentally, we introduce 
a simple method to generate a large amount of test cases based on a set 
of image pairs with viewpoint changes. Our results show that the 
proposed algorithm is generally superior to traditional approaches in 
finding correct correspondences.
\end{abstract}
%
\section{Introduction}
%
When matching feature points between two or more images we are often 
faced with the problem of correctly identifying the actual 
correspondences among many possible pairings. Several methods have been 
proposed in the literature to solve this problem. Many approaches look 
at the geometric configuration of feature points and match them based on 
various assumptions about the geometric relationship between the images. 
These assumptions are then used to create different constraints on the 
matches, e.g.\ angular constraints \cite{kim2008efficient}, epipolar 
constraints \cite{torr2000mlesac,chum2005matching}, or pairwise 
constraints \cite{choi2009robust,leordeanu2005spectral}.
%
%When matching feature points between two or more images we are often 
%faced with the problem of correctly identifying the actual 
%correspondences among many possible pairings. Several methods have been 
%proposed in the literature to solve this problem. In particular many 
%approaches look at the geometric configuration of the feature points 
%and match them according to assumptions made about the geometric 
%relationship between the images matched. A simple example would be to 
%only consider matches that aren't   too much with respect to the 
%average angle and distancen as considered by \cite{kim2008efficient}.  
%This performs well in situations where no camera rotation occurs 
%between the two images, but fails when this assumption isn't met. 
%Various scenarios have been proposed to improve on this simple 
%assumption such as epipolar constraints (\cite{torr2000mlesac}, 
%\cite{chum2005matching}) and pairwise constraints 
%(\cite{choi2009robust}, \cite{leordeanu2005spectral}). The Epipolar 
%constraint carries the assumption that the two images matched are 
%related by an affine transformation. That is, there is no relative 
%movement of objects in between images and either the viewpoint is fixed 
%or the image resides entirely on a plane. In practice this assumption 
%largely holds true when all objects we are interested in matching are 
%roughly the same distance from the camera and when we expect to match 
%objects that are consistently positioned across images.  Pairwise 
%constraints provide a more robust approach to the same problem by 
%looking at a set of proposed correspondences and defining a pairwise 
%error between any two matches for example based on the assumption that 
%two neighboring correspondences will usually have similar angles and 
%distances. We can then convert the problem to an optimization problem 
%and return a set of correspondences that minimizes this error such as 
%proposed in \cite{choi2009robust} and \cite{leordeanu2005spectral}.  
%This approach provides more robustness in cases where assumptions that 
%are violated globally still hold on a local scale.
%
An alternative is to pick out different areas in each image and pair 
areas when correspondence pairs are mainly found going from one area to 
another. This allows for the filtering of all correspondences that do 
not fall within paired areas. Examples include \emph{Isodata} 
\cite{das2008event}, which clusters feature points according to their 
position in the image, and the method from \cite{wu2011robust}, which 
uses maximally stable extremal regions (MSER) feature points to 
designate areas. In this paper the algorithm from \cite{das2008event} 
will later be referred to as \emph{Isodata}.

%proposes clustering feature points by using their geometric position 
%and exclude correspondences that are geometrically deviant. A more 
%sophisticated approach is introduced in \cite{wu2011robust} where the 
%areas are created by using the MSER feature detector to find areas of 
%interest in the images. These areas can be defined as an ellipse with a 
%certain radius around the interest points. The feature points that fall 
%within this ellipse are then matched according to epipolar constraints.  

In practice there are many situations where relying on the geometry of 
the image to filter correspondences is not possible, for example images 
without overlap, or adjacent objects in one image are that are separated 
in another.  Furthermore, methods using geometric constraints all 
require an initial set of correspondences. If this set of 
correspondences can be narrowed down to the most probable correct 
matches, the geometric matching algorithm will benefit in terms of speed 
and accuracy.  Finally some use cases might require a speed that simply 
cannot be achieved by complex geometric methods.

In the absence of geometric constraints, only few methods are available.  
As pointed out in \cite{szeliski2010}, the simplest approach to matching 
feature points is to return all matches above a given threshold of 
similarity.  This can be done with a fixed threshold or by finding the 
nearest neighbors for each point (still filtering by a threshold to 
avoid including matches for feature points that have no counterpart in 
the other image).  Lowe \cite{lowe2004sift} proposed the scale-invariant 
feature transform (SIFT) together with an alternative measure, where the 
uniqueness of a given match is found by looking at the two nearest 
neighbors of each feature point and calculating the matching score as 
the ratio of similarities.  Ranking the scores by their uniqueness and 
picking the $n$ best produces a set of correspondences that are 
distinctly matched across two images.
Of these three methods (fixed threshold, nearest neighbors, and 
\emph{SIFT}), \emph{SIFT} was found to perform best by a slight margin 
\cite{mikolajczyk2005performance}.

The two methods we propose in this paper are inspired by a simple but 
novel idea. If a given feature point in one image is better matched with 
other feature points from the \emph{same} image than points in the other 
image, then any matches from this feature point to points in the other 
image are considered unreliable and should be discarded.  This approach 
carries no implicit assumptions about the geometric consistency of 
matches and as such can easily be extended with other geometric 
solutions when appropriate or necessary.

Based on this idea,  we determine reliable matches as follows. 
\emph{Mirror Match (MM)} matches every feature from both images with all 
other features and filters matches based on the ratio of best to second 
best match as in \emph{SIFT}. \emph{Mirror Match with Clustering (MMC)} 
on the other hand takes the combined set of feature points from both 
images and clusters these points according to their descriptors.  If a 
resulting partition contains only feature points from one image, no 
matches are returned.  If the partition contains points from both 
images, \emph{Mirror Match} is used to find the best matches within this 
partition.  The experimental results show that both approaches generally 
outperform existing correspondence matching methods.

%Matching feature points against the entire set of points from both 
%images ensures that the distinctiveness of a returned correspondence is 
%higher. In almost all cases\footnote{Exceptions would include cases 
%where we want to find all particular points in a pattern and other use 
%cases where the correspondence isn't assumed to be unique}, a good 
%match between two images is unambiguous in the sense that there are no 
%other equally good potential matches to the same point.  This is the 
%key insight behind the algorithm presented by Lowe in 
%\cite{lowe2004sift}.  However the implication doesn't follow the other 
%way around. In the case that a feature point doesn't have a true 
%correspondence there might still exist point with which the feature 
%point is uniquely matched. The issue is particularly pronounced if we 
%compare two images that do not correspond. For any proposed 
%correspondence it is entirely probable that this correspondence is 
%unique even if it isn't correct. When we match against the feature 
%points of both images this ambiguity is avoided.  When the two images 
%have no overlap or objects in common, chances are that a feature point 
%will match better with another feature point from the same image in 
%which case it is easily discarded.
%
%Often images will contain repetitive patterns that are difficult to 
%match\footnote{In fact this particular problem has been given attention 
%before by for example \cite{fan2011towards}} because the feature 
%descriptors covering these patterns will be similar. If we remove points 
%that aren't deemed sufficiently unique like in \emph{MM} this means that 
%these points will often be discarded even if they are correctly matched.
%\emph{MMC} makes it possible to look at groups of similar feature points 
%one at a time and within each group find the best matches. This is done 
%by taking the set of feature points from both images and cluster them by 
%their similarity. In some cases the clustering will end up grouping 
%feature points of only one image together which can then easily be 
%discarded in the matching process.  In other cases partitions will 
%contain similar feature points from both images that can then be matched 
%using \emph{MM} but with much lower thresholds.
%

The paper is organized as follows.  Section~\ref{S:MatchingMethods} 
describes the proposed \emph{Mirror Match (MM)} and \emph{Mirror Match 
with Clustering (MMC)} algorithms.  Section~\ref{S:Experiments} presents 
the dataset used for evaluation and the experimental setup.  
Section~\ref{S:Results} discusses the benchmarking results obtained.  
Section~\ref{S:Summary} concludes the paper.  

\section{Matching Methods}
\label{S:MatchingMethods}

\subsection{Mirror Match (\emph{MM})}

\begin{figure}
	\centering%
		\begin{subfigure}[t]{\columnwidth}
			\centering
			\includegraphics[width=0.85\columnwidth]{images/MMC_pitts_source}
			\caption{Source image pair}
			\label{fig:pitts_source}
		\end{subfigure}%
		\\ %
		\begin{subfigure}[t]{\columnwidth}
			\centering
			\includegraphics[width=0.85\columnwidth]{images/MMC_pitts_keypoints}
			\caption{Feature points}
			\label{fig:pitts_keypoints}
		\end{subfigure}%
		\\ %add desired spacing between images, e. g. ~, \quad, 
		%\qquad (or a blank line to force the subfigure onto a new line)
		\begin{subfigure}[t]{\columnwidth}
			\centering
			\includegraphics[width=0.85\columnwidth]{images/mirror_match_off}
			\caption{\emph{SIFT}}
			\label{fig:unique}
		\end{subfigure}%
		\\ %add desired spacing between images, e. g. ~, \quad, 
		\begin{subfigure}[t]{\columnwidth}
			\centering
			\includegraphics[width=0.85\columnwidth]{images/mirror_match_with_pruned}
			\caption{\emph{MM} intermediate result}
			\label{fig:within}
		\end{subfigure}%
		\\ %add desired spacing between images, e. g. ~, \quad, 
		%\qquad (or a blank line to force the subfigure onto a new line)
		\begin{subfigure}[t]{\columnwidth}
			\centering
			\includegraphics[width=0.85\columnwidth]{images/mirror_match}
			\caption{\emph{MM} final result}
			\label{fig:without}
		\end{subfigure}%
		\\ %add desired spacing between images, e. g. ~, \quad, 
		\begin{subfigure}[t]{\columnwidth}
			\centering
			\includegraphics[width=0.85\columnwidth]{images/MMC_partition}
			\caption{\emph{MMC} Partition Example}
			\label{fig:pitts_partition}
		\end{subfigure}%
	\caption{Feature matching with \emph{MM} and \emph{MMC}. Dots represent feature points; green/red lines indicate correct/incorrect matches, respectively; black lines represent edges in the feature graph.  
	(c) Result of \emph{SIFT} matching. 
  (d) All matches found by \emph{MM}, including intra-image matches. 
	(e) Final \emph{MM} result. 
	(f) Example of a partition of feature points after clustering, which 
includes similar feature points from building windows and shirt patterns.}%
	\label{fig:comparemirror}%
\end{figure}%


%
The central idea behind \emph{MM} is to match features of $n$ images by 
taking every feature from all $n$ images and matching it against every 
other feature from the same set. We can then discard the correspondences 
that match two points within the same image. Algorithm~\ref{alg-mm} details  
the implementation of \emph{MM}.
%
\begin{algorithm}
\caption{Mirror Match (\emph{MM})}
\label{alg-mm}
%{\fontsize{10}{10}\selectfont
\begin{algorithmic}
\Require $images$ : set of images, $t \in \mathbb{R}$
\State $matches_{init}\gets \varnothing$
\State $matches_{final}\gets \varnothing$
\State $features\gets \varnothing$
\ForAll{$I_i \in images$} \Comment Acquisition Stage
	\State $features\gets features \cup getFeatures(I_i)$
\EndFor
\ForAll{$f_i \in features$} \Comment Matching Stage
	\State $f_m,f_n \gets get2NNs(f_i, features \setminus 
	\left\{f_i\right\})$
	\State $ratio \gets similarity(f_i, f_n) / similarity(f_i, f_m)$
	\If{$ratio < t$}
		\State $matches_{init} \gets \left(f_i, f_m\right)$
	\EndIf
\EndFor
\ForAll{$\left(f_i, f_j \right) \in matches_{init}$} \Comment Filter 
Stage
\If{$\left(f_j, f_i \right) \in matches_{init} \wedge getImg(f_i) \neq 
getImg(f_j) \wedge \left(f_j, f_i\right) \not\in matches_{final}$}
		\State $matches_{final} \gets (f_i, f_j)$
	\EndIf
\EndFor \\
\Return $matches_{final}$
\end{algorithmic}
%}
\end{algorithm}
%
In the acquisition stage we gather all features in the set of images.  
In the matching stage these features are matched using $k$-nearest 
neighbors.  For any given feature $f_i$ the two most similar neighbors 
are returned, and we calculate the ratio between them as proposed in 
\cite{lowe2004sift}.  Any correspondence with a ratio above the 
threshold supplied will be discarded. Finally in the filter stage we 
check that matches are from different images and discard all matches 
that are not symmetric.
%
%\begin{figure*}
%	\makebox[\textwidth][c]{%
%		\begin{subfigure}[t]{0.32\textwidth}
%			\centering
%			\includegraphics[width=\textwidth]{images/MMC_pitts_source}
%			\caption{Source image pair}
%			\label{fig:pitts_source}
%		\end{subfigure}%
%		\enspace %
%		\begin{subfigure}[t]{0.32\textwidth}
%			\centering
%			\includegraphics[width=\textwidth]{images/MMC_pitts_keypoints}
%			\caption{Feature points}
%			\label{fig:pitts_keypoints}
%		\end{subfigure}%
%		\enspace %add desired spacing between images, e. g. ~, \quad, 
%		%\qquad (or a blank line to force the subfigure onto a new line)
%		\begin{subfigure}[t]{0.32\textwidth}
%			\centering
%			\includegraphics[width=\textwidth]{images/mirror_match_off}
%			\caption{\emph{SIFT}}
%			\label{fig:unique}
%		\end{subfigure}%
%	}
%	\makebox[\textwidth][c]{%
%		\begin{subfigure}[t]{0.32\textwidth}
%			\centering
%			\includegraphics[width=\textwidth]{images/mirror_match_with_pruned}
%			\caption{\emph{MM} intermediate result}
%			\label{fig:within}
%		\end{subfigure}%
%		\enspace %add desired spacing between images, e. g. ~, \quad, 
%		%\qquad (or a blank line to force the subfigure onto a new line)
%		\begin{subfigure}[t]{0.32\textwidth}
%			\centering
%			\includegraphics[width=\textwidth]{images/mirror_match}
%			\caption{\emph{MM} final result}
%			\label{fig:without}
%		\end{subfigure}%
%		\enspace%
%		\begin{subfigure}[t]{0.32\textwidth}
%			\centering
%			\includegraphics[width=\textwidth]{images/MMC_partition}
%			\caption{\emph{MMC} Partition Example}
%			\label{fig:pitts_partition}
%		\end{subfigure}%
%	}%
%	\caption{Illustration of feature matching with \emph{MM} and \emph{MMC}. Dots represent feature points; green/red lines indicate %correct/incorrect matches, respectively; black lines represent edges in the feature graph.  
%(c) Result of \emph{SIFT} matching the two images.% 
%  (d) All matches found by \emph{MM}, including matches between points in the same image. 
%	(e) Final \emph{MM} result with the intra-image matches removed. 
%	(f) Example of a partition of feature points after clustering. This partition 
%includes similar feature points around the windows of a building and the patterns of a shirt.}%
%	\label{fig:comparemirror}%
%\end{figure*}%


Figure~\ref{fig:comparemirror} illustrates the benefits of \emph{MM} 
using an example image pair from the Gallagher dataset 
\cite{gallagher2008}.
With \emph{SIFT} (Figure~\ref{fig:unique}), many incorrect matches occur 
in the fence towards the bottom of the image.
When we match all feature points together, many of these incorrect 
matches are eliminated, because points in the fence match with other 
points in the fence in the same image (Figures~\ref{fig:within} and
\ref{fig:without}).


\subsection{Mirror Match with Clustering (\emph{MMC})}
%
In contrast to \emph{MM}, \emph{MMC} diverges from traditional 
non-geometric feature matching by clustering feature points by 
similarity. This process yields partitions of fairly similar feature 
points that we can match using the same approach as \emph{MM}.  
Algorithm~\ref{alg-mmc} shows the pseudocode implementation of \emph{MMC}.
%
%Before we introduce the implementation details we will go over the 
%problem of graph clustering and how it relates to feature matching.
%
%\subsubsection{Graph Clustering}
%
%Given a set of feature points from two images, $im_1$ and $im_2$: $F_k = 
%\{k_i, k_j$ for $k_i \in im_1, k_j \in im_2\}$ as well as a matching 
%function $M(k_i, k_j) \rightarrow \mathbb{R}$ that takes two feature 
%points in an image and returns their matching score, we can define a 
%matrix $A$ where each element $A_ij = M(k_i, k_j)$. A can be interpreted 
%as the \emph{adjecency matrix} of the fully connected graph where each 
%vertex corresponds to a keypoint and the edge between two vertices has a 
%weight equal to the distance between the two corresponding keypoints.
%
%This representation reduces the problem of partitioning the keypoints 
%into groups to that of graph clustering or community structure depending 
%on the context. In the literature there are various ways of clustering a 
%graph according to different measures of what constitutes an optimal 
%partitioning. Traditionally the most used clustering algorithms have 
%been K-means and spectral clustering, but in recent years a host of new 
%algorithms have been proposed based on both Newman's concept of graph 
%modularity\footnote{Introduced in \cite{girvan2002}, discussed in 
%\cite{brandes2007} and used in \cite{blondel2008} as well as others} as 
%well as information theoretical measures\footnote{See for example 
%\cite{rosvall2008}} and the Potts spin model from physics\footnote{Used 
%in \cite{ronhovde2009}} just to mention a few approaches. Many of the 
%new algorithms differ from K-means clustering and Spectral clustering 
%in that they do not require the number of expected to clusters to be 
%specified beforehand\footnote{Among the aforementioned methods, this is 
%true for \cite{blondel2008} and \cite{rosvall2008}}.  Furthermore, on 
%tests done using randomly generated graphs with a known partitioning 
%\cite{blondel2008}, \cite{rosvall2008} and \cite{ronhovde2009} perform 
%markedly better than spectral clustering and 
%K-means\cite{lancichinetti2009}.
%
%The performance of clustering algorithms is a complicated issue, since 
%an optimal clustering given the same graph can vary depending on the 
%application. Spectral clustering for example will usually return a 
%partitioning where each partition is roughly equal in size\footnote{As 
%mentioned in \cite{von2007}} while the Louvain 
%clustering\cite{blondel2008} might return partitions of very uneven 
%size, even if the modularity measurement has been shown to penalize very 
%small clusters\cite{brandes2007}. Both behaviours can be beneficial 
%depending on the application, but when clustering feature points, 
%maintaining clusters of an even size usually means that some clusters 
%will be '\emph{catch-all}' clusters where the feature points that do 
%not fit anywhere else are grouped together. The necessity of specifying 
%the amount of partitions in for example Spectral clustering or Pott's 
%model clustering further exacerbates the issue since smaller partitions 
%are then combined into one to achieve the right amount of partitions.
%

%
\begin{algorithm}
\caption{Mirror Match with Clustering (\emph{MMC})}
\label{alg-mmc}
%{\fontsize{10}{10}\selectfont
\begin{algorithmic}
\Require $images$ : set of images, $t \in \mathbb{R}$
\State $M\gets \varnothing$
\State $F\gets \varnothing$
\ForAll{$I_i \in images$} \Comment Gather features
	\State $f_i\gets getFeatures(I_i)$
	\State $F\gets F \cup f_i$
\EndFor
\State $A\gets getAdjacencyMatrix(f_1, f_2,\; \ldots \;, f_n)$
\State $A_{norm}\gets 1 - normalize(A)$
\State $A_{pruned}\gets pruneEdges(A_{norm},\alpha)$
\State $P\gets cluster(A_{pruned})$
\ForAll{$p \in P$} \Comment p is a set of feature points
	\State $M\gets M \cup getMatches(p, t, F)$
\EndFor \\
\Return matches
\end{algorithmic}
%}
\end{algorithm}

\begin{figure}[h]
	\centering
	\begin{subfigure}{0.8\columnwidth}
		\includegraphics[width=\columnwidth]{images/MMC_graph_full}
		\caption{Full Graph}
		\label{fig:full_graph}
	\end{subfigure}%

	%add desired spacing between images, e. g. ~, \quad, \qquad		  
	%(or a blank line to force the subfigure onto a new line)
	\begin{subfigure}{0.7\columnwidth}
		\includegraphics[width=\columnwidth]{images/MMC_graph_cropped}
		\caption{Cropped Section of Graph}
		\label{fig:cropped_graph}
	\end{subfigure}%
	\caption{The partitioned feature graph (a). Each vertex represents a 
		feature point; lines indicate high similarity between 
		points. A partition is a connected group with the same color. The border color of each node 
		indicates which image it belongs to.  Zooming into a section of the graph (b), the various cluster sizes can be seen, ranging from 
	hundreds of feature points to only two or three.}
	\label{fig:graph}
\end{figure}

We use the Louvain Method \cite{blondel2008} for clustering feature 
points, since it is relatively fast and performs 
well \cite{lancichinetti2009}, does not require 
parameters \cite{blondel2008}, and does not emphasize partitions of equal 
size, as opposed to spectral clustering or 
k-means \cite{von2007}, for example.
While the Louvain clustering algorithm does not require any parameters in 
itself, it tends towards clustering all feature points together in the 
same partition if the graph is very connected.  To ensure that the graph 
is well clustered, the adjacency matrix is pruned so that only edges above a 
certain threshold are kept. From empirical analysis, retaining the top 
2.5\% of edges with the highest similarity seems to work well in 
practice. Figure~\ref{fig:graph} shows the result of clustering the 
feature points as a graph.
%

The partitions group feature points by similarity, which means that 
repetitive structures such as buildings often appear in larger 
partitions, as exemplified in Figure~\ref{fig:pitts_partition}.
%
%\begin{figure}
%	\makebox[0.5\textwidth][c]{%
%		\begin{subfigure}[t]{0.24\textwidth}
%			\centering
%			\includegraphics[width=\textwidth]{images/MMC_pitts_source}
%			\caption{Source image}
%			\label{fig:pitts_source}
%		\end{subfigure}%
%		~ %add desired spacing between images, e. g. ~, \quad, \qquad		  
%		%(or a blank line to force the subfigure onto a new line)
%	}%
%	\\
%	\makebox[0.5\textwidth][c]{
%		%~ %add desired spacing between images, e. g. ~, \quad, \qquad		  
%		%(or a blank line to force the subfigure onto a new line)
%		
%		\begin{subfigure}[t]{0.5\textwidth}
%			\centering
%			\includegraphics[width=\textwidth]{images/MMC_partition}
%			\caption{A Partition Example}
%			\label{fig:pitts_partition}
%		\end{subfigure}%
%	}%
%	\caption{Example of a partition of keypoints in an image pair. The 
%		partition shown contains window corners from a building in the 
%		left image and similar corners on the shirt in the right image.  
%	}
%	\label{fig:compare_mirror}
%\end{figure}
%
%The matching algorithm for \emph{MMC} (algorithm \ref{alg-getmatches}) 
%goes through the partitions one by one and selects matches in the 
%following way: If the partition has no edges going from a feature point 
%in one image to a feature point in another image, the partition is 
%discarded. If we have more than one edge going between images then 
%$getMatches$ will behave as \emph{MM} and make sure that a 
%correspondence is symmetric, that it has a ratio above the desired 
%threshold and that it isn't matching two feature points from the same 
%image. Since feature points are all guaranteed to be fairly similar 
%this means that we can set the ratio threshold much higher than in 
%\emph{MM} and include matches that would normally have been discarded 
%for not being sufficiently unique.

The matching algorithm for \emph{MMC}, \emph{getMatches}, finds matches 
within all partitions with more than two elements using the \emph{MM} 
approach.  However, as can be seen in the example in 
Figure~\ref{fig:cropped_graph}, many of the partitions contain only two 
feature points from different images linked by one edge. In such a case, 
we compare the similarity of the these two feature points with their 
second best match and remove matches where this ratio lies above a 
certain threshold, like in the \emph{SIFT} algorithm. For example in the 
case of Figure~\ref{fig:pitts_partition}, we have feature points from a 
building in one image grouped together with points from a shirt pattern 
in another.  The nearest neighbor method would have returned wrong 
matches, but since we match the partition with \emph{MM}, points in the 
building end up matching other points in the building, and no matches 
are returned.

%\begin{algorithm}
%\caption{Impl. of getMatches (\emph{from MMC algorithm})}
%\label{alg-getmatches}
%{\fontsize{10}{10}\selectfont
%\begin{algorithmic}
%\Require $p$ : set of features, $t\in \mathbb{R}$, $features$ : Set of 
%all features
%\State $matches \gets \varnothing$
%\State $edges \gets \left\{similarity(f_i, f_j) \mid getImg(f_i) \neq 
%	getImg(f_j)$
%\State $\wedge f_i, f_j \in p \right\}$
%\If{$\left\vert edges \right\vert = 1$} \Comment If $\exists$ one edge 
%between images
%	\State $f_i,f_j \gets getFeatures(edges_{inter}, p)$
%	\State $f_m,f_n \gets get2NNs(f_i, features ~ 
%\setminus ~ \left\{f_i\right\})$
%	\State $f_s,f_t \gets get2NNs(f_j, features ~ 
%\setminus ~ \left\{f_j\right\})$
%	\State $ratio_i \gets similarity(f_i, f_n) / similarity(f_i, 
%f_j)$
%	\State $ratio_j \gets similarity(f_j, f_t) / similarity(f_j, 
%f_i)$
%	\If{$ratio_i < t\wedge ratio_j < t$}
%		\State $matches \gets matches \cup (f_i, f_j)$
%	\EndIf
%\ElsIf{$\left\vert edges \right\vert > 1$} \Comment If $\exists$ more 
%than one edge between images
%	\ForAll{$f_i \in p$}
%		\State $f_m,f_n \gets get2NNs(f_i, p \setminus 
%\left\{f_i\right\})$
%		\State $ratio \gets similarity(f_i, f_n) / similarity(f_i, 
%f_m)$
%		\If{$getImg(f_i) \neq getImg(f_m) \wedge ratio < t
%\wedge (f_m, f_i) \not\in matches$}
%			\State $matches \gets matches \cup (f_i, f_m)$
%		\EndIf
%	\EndFor
%\EndIf
%
%\Return matches
%\end{algorithmic}
%}
%\end{algorithm}

\section{Experiments}
\label{S:Experiments}
%
To reliably measure the accuracy of a matching method on real images, we 
either need a set of image pairs tied by a homography, or we have to manually count 
the number of inliers. The latter becomes prohibitive for large numbers of (non-trivial) images. 

Mikolajczyk and Schmid  \cite{mikolajczyk2005performance} introduced a set of test images
to compare the performance of feature detectors. The 
set covers different types of image variations, such as lighting change, 
blur, rotation, and viewpoint change. Inspired by this 
dataset (in particular the `Graf' image set) and motivated by 
the need for more image pairs featuring viewpoint changes, we have 
compiled a set of 8 image pairs consisting of subjects taken from two 
different angles. The images are collected from Flickr's database of 
images published under a creative commons 
licence %\footnote{\href{http://creativecommons.org/}{www.creativecommons.org}, 
%a copyleft license permitting redistribution} 
and feature murals, which 
makes it possible to relate points in the image pairs with a homography.  
The images have been cropped to show the same motive and resized to 
$900\times 600$ pixels.  This dataset will be referred to as the 
\emph{Murals} dataset.  Figure~\ref{fig:murals} shows one image from each pair.

\begin{figure}[htb]
%	\makebox[0.5\textwidth][c]{%
%		\begin{subfigure}[t]{0.048\textwidth}
%			\centering
%			\includegraphics[width=\textwidth]{images/pair_example1}
%			\label{fig:fairey1}
%	\end{subfigure}%
%		\enspace %add desired spacing between images, e. g. ~, \quad, 
%		%(or a blank line to force the subfigure onto a new line)
%		\begin{subfigure}[t]{0.048\textwidth}
%			\centering
%			\includegraphics[width=\textwidth]{images/pair_example2}
%			\label{fig:fairey2}
%		\end{subfigure}%
%		\enspace %
%		\begin{subfigure}[t]{0.36\textwidth}
			\centering
			\includegraphics[width=\columnwidth]{images/crop_examples}
%		\end{subfigure}%
%	}%
	\caption{Sample test patches produced from an image pair.}
	\label{fig:fairey}
\end{figure}

\begin{figure*}[t]
	\centering
	\includegraphics[width=\textwidth]{images/murals}
	\caption{Images in the \emph{Murals} test set.}
	\label{fig:murals}
\end{figure*}

\begin{figure}[htb]
	\centering
	\includegraphics[width=\columnwidth]{images/graf12345.jpg}
	\caption{Images 1-5 of the Graf set from \cite{mikolajczyk2005performance}.}
	\label{fig:Graf}
\end{figure}


%However in practice the view point change has gone on to be used the 
%most for later tests given that most of the other test pairs have since 
%become easy to match\footnote{see \cite{wu2011robust} or 
%\cite{delponte2006svd} for examples}.

%Inspired by the graffiti image we have collected a set of image pairs 
%featuring murals of a few different artists\footnote{Including Banksy, 
%Blu and Shepard Fairey among others}. Each pair consist of images of 
%the same motive taken from different angles, often including repetitive 
%patterns and texture. Based on this image set the two algorithms are 
%tested on a series of image patches from each pair. To verify that the 
%algorithms proposed are reliable we need to test that we get good 
%matches when images overlap and that we get no matches when they do 
%not.  This means that it isn't enough just testing against pairs of 
%images that we know match.  We also need to test against pairs that 
%might look like they could match but in fact do not.


%
%
%\subsection{Experimental setup}
We compare the \emph{MM} and \emph{MMC} algorithms to 
\emph{SIFT} \cite{lowe2004sift} as well 
as \emph{Isodata} \cite{das2008event}. 
\emph{Isodata} uses geometric constraints, whereas \emph{SIFT} does not.
%, which uses geometric information to improve the matching. 
%The comparison  with \emph{SIFT} serves to illustrate the relative performance of 
%\emph{MM} and \emph{MMC} to a state of the art algorithm without 
%geometric constraints. \emph{Isodata} is included to 
%illustrate the performance of an algorithm relying on geometric 
%constraints faced with image pairs that might not have any overlap.  
The 
comparison was done using the \emph{Murals} dataset (Figure~\ref{fig:murals}), the 
\emph{Graf} set (Figure~\ref{fig:Graf}) from \cite{mikolajczyk2005performance}, and two 
images %\footnote{100\_1942.jpg and 100\_1941.jpg} 
from the Gallagher dataset \cite{gallagher2008} (Figure~\ref{fig:comparemirror}).

Test sets were generated from the image pairs by cropping square patches of
$250\!\times\!250$ pixels with a random vertical and horizontal offset.  
Given a source image pair, we produce 100 pairs of patches, which might or might not overlap.  
This ensures that patch pairs with no overlap still retain a general similarity to each 
other, while patches that do overlap often only share a small 
part of their area. Figure~\ref{fig:fairey} shows an example of 
possible pairs of test image patches produced from a source image pair.  
Producing $n$ such pairs allows us to test not just how well the 
matching algorithm performs on a variety of overlaps but also how many 
false positives we get on similar images that do not overlap at 
all.\footnote{~The set of source images and homographies as well as the 
script to generate the cropped test sets based on them will be made 
available online, together with the exact test sets used in this paper 
upon acceptance.}
%\href{https://github.com/arnfred/Murals}{www.github.com/arnfred/Murals}}.  
In practice the amount of overlap between pairs in a test set will 
depend on the overlap and viewpoint change in the source image pair.  To 
give a rough idea, Table~\ref{table:overlap} 
shows the overlap of patch pairs created from images 1 and 3 of the 
\emph{Graf} image set from \cite{mikolajczyk2005performance}.

\begin{table}[htb]
\caption{Overlap in the set of 100 patch pairs created from two images of the \emph{Graf} image set (Figure~\ref{fig:Graf}).}
\label{table:overlap}
	\centering
%	\small
\begin{tabular}{r*{3}{r}}
\hline
	Amount of overlap: & 0\% & $< 50$\% & $> 50$\%  \\
	\noalign{\smallskip}
	%
	Number of patch pairs: & 21 & 54 & 25 \\
	\hline
\end{tabular}
\end{table}


Given a potential match between two pixels $p_1$ and 
$p_2$, $m = \left(p_1, p_2\right)$, and a homography $H$ relating the two images $I_1$ and $I_2$, we 
can calculate if $m$ is an inlier by checking if the two points satisfy the following criteria:
\begin{equation*}
\left\vert H p_1 - p_2 \right\vert + \left\vert H^{-1}p_2 - p_1 \right\vert < d_{\max}
\end{equation*}
That is, the distance between $p_1$ translated to $I_2$ and $p_2$ 
\emph{plus} the distance between $p_2$ translated to $I_1$ should be 
less than a certain threshold (we use $d_{\max}=5$ pixels here).


\section{Results}
\label{S:Results}

Figure~\ref{fig:result_graf} shows the results for 100 patch pairs 
generated from images 1 and 3 of the \emph{Graf} image set (cf.~Figure~\ref{fig:Graf}). The plot 
compares the accuracy of \emph{SIFT}, \emph{MM}, \emph{MMC}, and 
\emph{Isodata} as a function of the number of matches produced (which is achieved by varying thresholds over a certain range). The results show that \emph{MM} and \emph{MMC} consistently outperform \emph{SIFT}; \emph{MMC} generally lies 2-3 percentage points above \emph{MM} when both are performing at optimal accuracy. 
Although \emph{Isodata} exhibits a good performance on strict thresholds (small number of matches), that quickly diminishes when more matches are desired.


\begin{figure}[htb]
%	\makebox[0.5\textwidth][c]{%
%		\begin{subfigure}[t]{.13\textwidth}
%			\centering
%			\includegraphics[width=\textwidth]{images/graf}
%		\end{subfigure}%
%		~ %add desired spacing between images, e. g. ~, \quad, \qquad		  
		%(or a blank line to force the subfigure onto a new line)
%		\begin{subfigure}[t]{.27\textwidth}
			\centering
			\includegraphics[width=0.6\columnwidth]{images/result_graf}
			%\caption{Performance on Scharf}
%		\end{subfigure}%
%	}%
	\caption{Accuracy for image pair 1\&3 from the \emph{Graf} set. The plot 
		shows the result of 100 patch pairs generated from the source 
		images shown to the left. The number of matches is the total 
		number of matches for all 100 patch pairs.}
	\label{fig:result_graf}
\end{figure}

To validate whether these results 
generalize to other images, we tested the four algorithms on the 
\emph{Murals} dataset as well as the \emph{Graf} pair tested above.  
In total 900 different patch pairs were generated from 9 
source image pairs.  The results are shown in Figure 
\ref{fig:result_accumulated}. 

\begin{figure}[htb]
	\centering
	\includegraphics[width=\columnwidth]{images/result_accumulated}
	\caption{Results for 900 patch pairs extracted from the \emph{Murals} dataset and the image pair 1\&3 from the \emph{Graf} set.  The x-axis shows the accumulated returned matches for all pairs.}
	\label{fig:result_accumulated}
\end{figure}

To further investigate the impact of viewpoint changes, we tested the 
algorithms on the \emph{Graf} image set (Figure~\ref{fig:Graf}), which 
contains 5 images of the same mural taken with gradually increasing 
viewpoint changes.  The first images are almost identical, while the 
last are taken from very different angles. The results from   \emph{MMC} 
and \emph{SIFT} as shown in Figure~\ref{fig:result_viewpoint}, 
confirming that \emph{MMC} is generally superior to \emph{SIFT} across 
viewpoint changes.
The performance of \emph{MM} (not shown in the plot) is similar to 
\emph{MMC}.

\begin{figure}[htb]
	\centering
	\includegraphics[width=0.45\textwidth]{images/result_viewpoint}
	\caption{Results for viewpoint changes using the \emph{Graf} set from 
		\cite{mikolajczyk2005performance}.  S: img1\&2; M: img1\&3; L: img1\&4; XL: img1\&5.}
	\label{fig:result_viewpoint}
\end{figure}


Finally, for an example of a real life use case, Figure~\ref{fig:result_pitts} 
shows the results on 100 patch pairs generated 
from a typical holiday photo shot (Figure~\ref{fig:pitts_source}) featuring occlusion and a slight viewpoint 
change from the Gallagher dataset \cite{gallagher2008}.  The performance is comparable to the murals, despite the lack of a simple homographic mapping between the images.


\begin{figure}[htb]
%	\makebox[0.5\textwidth][c]{%
%		\begin{subfigure}[t]{.15\textwidth}
%			\centering
%			\includegraphics[width=\textwidth]{images/pitts}
%		\end{subfigure}%
		~%add desired spacing between images, e. g. ~, \quad, \qquad
		%(or a blank line to force the subfigure onto a new line)
%		\begin{subfigure}[t]{.27\textwidth}
			\centering
			\includegraphics[width=0.6\columnwidth]{images/result_pitts}
			%\caption{Performance on Scharf}
%		\end{subfigure}%
%	}%
	\caption{Results for the image pair in Figure~\ref{fig:pitts_source}.}
	\label{fig:result_pitts}
\end{figure}


In terms of computational complexity, \emph{SIFT}, \emph{MM}, and \emph{Isodata} can be 
implemented in $O(n\log n)$, where $n$ is the total number of feature 
points.  Our current \emph{MMC} implementation has a complexity of $O(n^2)$ due to the 
construction of a similarity matrix of the feature points. However, it is 
possible to approximate this in $O(n\log n)$ using search trees.  

In terms of speed, Table~\ref{table:running_times} shows the 
running time of the four algorithms over 100 image pairs of $250\!\times\!250$ pixels. 
These numbers should be taken with a grain of salt, given that 
much of the code behind \emph{MMC} and \emph{Isodata} is implemented in 
Python, whereas \emph{MM} and \emph{SIFT} make use of OpenCV to execute 
computationally intensive operations in C++, which makes them much 
faster. 

\begin{table}[htb]
\caption{Running times as tested on a Intel\textregistered\ Core\texttrademark\ i5-3550 CPU @ 
3.30~GHz with 8~GB memory.}
\label{table:running_times}
	\centering
%	\small
\begin{tabular}{r*{4}{c}}
\hline
	Algorithm: & \emph{SIFT} & \emph{MM} & \emph{MMC} & \emph{Isodata} 
	\\
	\noalign{\smallskip} 
	%
	Running time: & 20.94s & 18.23s & 883.99s & 555.33s \\
	\hline
\end{tabular}
\end{table}
%

\section{Summary}
\label{S:Summary}

We have addressed the problem of matching feature points without using 
geometrical constraints, proposing \emph{Mirror Match 
(MM)} and \emph{Mirror Match with Clustering (MMC)}.  The two algorithms 
share the common idea that feature points should have better 
matches in another image than in the image they came from to be 
considered good matches.  \emph{MMC} further improves on this idea by 
using the structure of the similarity graph of the feature points. 

The algorithms show promising results when tested on the \emph{Murals} data 
set. %, where pairs of the same object seen from different angles are %cropped to have different degrees of overlap ranging from full to non at all. The results on 900 patch pairs show that 
\emph{MM} and \emph{MMC} 
generally outperform existing matching algorithms \emph{SIFT} and \emph{Isodata}, and \emph{MMC} 
outperforms \emph{MM}. We show that this result generalizes to 
variations in viewpoint change as well as more realistic photos featuring occlusions. 
% by comparing \emph{MMC} to \emph{SIFT} over a set of image pairs with an increasing magnitude of perspective difference. 
%We go on to apply the algorithms to a real life image case 
%featuring occlusion and a slight viewpoint change and show that the 
%performance of \emph{MM} and \emph{MMC} is consistent with the results 
%on \emph{Murals}.  

Given the versatility of the proposed algorithms, we are planning to apply them to problems that require high 
reliability faced with images that might not match, such as near 
duplicate detection or face recognition.
%
\bibliographystyle{IEEEtran}
\bibliography{bibliography}
\end{document}
