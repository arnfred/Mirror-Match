{
 "metadata": {
  "name": "Recursive clustering"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Stupid hack to load files from sibling dir\n",
      "import sys; import os\n",
      "sys.path.insert(0, os.path.abspath('..'))\n",
      "\n",
      "%load_ext autoreload\n",
      "%autoreload 2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import display\n",
      "import weightMatrix\n",
      "import matching\n",
      "import louvainmatch\n",
      "import louvain\n",
      "import features\n",
      "import numpy\n",
      "import scoring\n",
      "import cv2\n",
      "from itertools import combinations"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "paths = ['../../images/gallagher/partial_match/skyline3_2.jpg', '../../images/gallagher/partial_match/skyline2_1.jpg']\n",
      "paths = ['../../images/florian/lion_1.jpg', '../../images/florian/freddy_1.jpg']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Get images\n",
      "images = map(features.loadImage, paths)\n",
      "keypoint_type = \"ORB\"\n",
      "descriptor_type = \"BRIEF\"\n",
      "\n",
      "# Get keypoints\n",
      "indices, ks, ds = features.getFeatures(paths, keypoint_type, descriptor_type)\n",
      "pos = features.getPositions(ks)\n",
      "positions = numpy.array(pos)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "try :\n",
      "    def getHomographyPath(paths) :\n",
      "        d = \"/\".join(paths[0].split('/')[0:-1])\n",
      "        p1 = paths[0].split('/')[-1].split(\".\")[0]\n",
      "        p2 = paths[1].split('/')[-1].split(\".\")[0]\n",
      "        return \"%s/%s_%s_hom.npy\" % (d, p1, p2)\n",
      "    homography_path = getHomographyPath(paths)\n",
      "    with open(homography_path) :\n",
      "        homography = numpy.loadtxt(homography_path)\n",
      "# In case the file doesn't exist, try to estimate something\n",
      "except IOError :\n",
      "    print(\"estimating homography\")\n",
      "    # Use cv2's matcher to get matching feature points\n",
      "    bfMatches = features.bfMatch(descriptor_type, ds[indices == 0], ds[indices == 1])\n",
      "        \n",
      "    # Get matches in usual format\n",
      "    def matchFromIndex(i,j) :\n",
      "        return (features.getPosition(ks[indices == 0][i]), features.getPosition(ks[indices == 1][j]))\n",
      "    \n",
      "    match_score = [(matchFromIndex(j,i), s, u) for j,(i,s,u) in enumerate(zip(*bfMatches)) if i != None and u < 0.8]\n",
      "    matches, scores, uniques = zip(*match_score)\n",
      "    \n",
      "    match_1, match_2 = zip(*matches)\n",
      "    homography, blup = cv2.findHomography(numpy.array(match_1), numpy.array(match_2), cv2.RANSAC)\n",
      "print(homography)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "estimating homography\n",
        "[[  9.74377026e-02  -6.41501460e-01   1.48628615e+02]\n",
        " [  1.71412005e-01  -1.19685635e+00   2.78246381e+02]\n",
        " [  5.82603634e-04  -4.26341085e-03   1.00000000e+00]]\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Get parameters\n",
      "options = {}\n",
      "prune_fun = options.get(\"prune_fun\", weightMatrix.pruneTreshold)\n",
      "prune_limit = options.get(\"prune_limit\", 4.5)\n",
      "min_edges = options.get(\"min_edges\", 1)\n",
      "weight_limit = options.get(\"weight_limit\", -1.0)\n",
      "min_coherence = options.get(\"min_coherence\", -1.0)\n",
      "keypoint_type = options.get(\"keypoint_type\", \"ORB\")\n",
      "descriptor_type = options.get(\"descriptor_type\", \"BRIEF\")\n",
      "\n",
      "# Get all feature points\n",
      "indices, ks, ds = features.getFeatures(paths, keypoint_type = keypoint_type, descriptor_type = descriptor_type)\n",
      "\n",
      "# Calculate weight matrix (hamming distances)\n",
      "full_weights = weightMatrix.init(ds, louvainmatch.dist_fun_map[descriptor_type])\n",
      "\n",
      "# Get geometric weights\n",
      "if weight_limit != -1.0 : weights = louvainmatch.getGeom(full_weights, ks, indices, weight_limit)\n",
      "else : weights = full_weights\n",
      "\n",
      "# Get cluster weights\n",
      "cluster_weights = prune_fun(weights, prune_limit)\n",
      "\n",
      "# Cluster graph\n",
      "#partitions = louvain.cluster(cluster_weights, verbose=True)\n",
      "#print(\"%i partitions\" % len(set(partitions)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def cluster(weights, indices, split_limit = 10, prune_limit = 3, indent = \"\") :\n",
      "    partitions = louvain.cluster(weights, verbose=False)\n",
      "    p_set = set(partitions)\n",
      "    \n",
      "    r = numpy.arange(0, weights.shape[0])\n",
      "    for p in p_set :\n",
      "        partition_mask = partitions == p\n",
      "        for i,j in combinations(set(indices),2) :\n",
      "            # Set up masks\n",
      "            row_mask = partition_mask & (indices == i)\n",
      "            col_mask = partition_mask & (indices == j)\n",
      "            index_row = r[row_mask]\n",
      "            index_col = r[col_mask]\n",
      "    \n",
      "            # Get weights\n",
      "            pij_edges = weights[row_mask][:,col_mask]\n",
      "            p_edges = weights[partition_mask][:,partition_mask]\n",
      "            nb_inter_edges = numpy.sum(pij_edges > 0)\n",
      "            if (nb_inter_edges > split_limit) :\n",
      "                # Prune weights\n",
      "                p_edges_pruned = weightMatrix.pruneTreshold(p_edges, prune_limit)\n",
      "                # normalizing weights\n",
      "                p_max = numpy.max(p_edges_pruned)\n",
      "                p_min = numpy.min(p_edges_pruned.nonzero())\n",
      "                p_zero = p_edges_pruned == 0\n",
      "                p_edges_norm = (p_edges_pruned - p_min) / (p_max - p_min)\n",
      "                p_edges_norm[p_zero] = 0\n",
      "                \n",
      "                # cluster\n",
      "                p_partition = cluster(p_edges_norm, indices[partition_mask], split_limit, prune_limit)\n",
      "            \n",
      "                # Update partitioning\n",
      "                partitions[partition_mask] = p_partition + numpy.max(partitions) + 1\n",
      "    return partitions"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# cluster feature points\n",
      "partitions = cluster(cluster_weights, indices)\n",
      "print(\"%i partitions\" % len(set(partitions)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "198 partitions\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getPartitionMatches(partitions, weights, indices, min_edges = 1, min_coherence = -1.0) :\n",
      "    \n",
      "    # index\n",
      "    r = numpy.arange(0, weights.shape[0])\n",
      "    # Get numpy array of indices\n",
      "    for p in set(partitions) :\n",
      "    \n",
      "        partition_mask = partitions == p\n",
      "        partition_weights = weights[partition_mask][:, partition_mask]\n",
      "        for i,j in combinations(set(indices),2) :\n",
      "    \n",
      "            # Set up masks\n",
      "            row_mask = partition_mask & (indices == i)\n",
      "            col_mask = partition_mask & (indices == j)\n",
      "            index_row = r[row_mask]\n",
      "            index_col = r[col_mask]\n",
      "    \n",
      "            # Get weights\n",
      "            pij_edges = weights[row_mask][:,col_mask]\n",
      "            \n",
      "            c = louvainmatch.getCoherence(partition_weights, partition_mask, indices, i, j)\n",
      "            nb_e = numpy.sum(pij_edges > 0)\n",
      "            if nb_e >= 1 :\n",
      "                \n",
      "                #pairs = [numpy.unravel_index(index, pij_edges.shape) for index in pij_edges.argsort(axis=None)[::-1]]\n",
      "                sd0,sd1 = scoring.getPartitionDeviation(partition_mask, (indices == i, indices == j), ks)\n",
      "                \n",
      "                #pairs_pos = [(features.getPosition(ks[index_row[i]]), features.getPosition(ks[index_col[j]])) for (i,j) in pairs]\n",
      "                (m_i, m_j) = numpy.unravel_index(pij_edges.argmax(), pij_edges.shape)\n",
      "                distance = matching.matchDistance(ks[index_row[m_i]].pt, ks[index_col[m_j]].pt, homography)\n",
      "                print(\"%4i\\tsd0: %.2f\\tsd1: %.2f\\tch: %.3f\\tEdges: %i\\tDistance: %.2f\" % (p, sd0, sd1, c, nb_e, distance))\n",
      "                yield (index_row[m_i], index_col[m_j])\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "matches = getPartitionMatches(partitions, cluster_weights, indices)\n",
      "l = list(matches)\n",
      "print(len(l))\n",
      "#print(list(matches))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1103\tsd0: 3.87\tsd1: 0.00\tch: 0.002\tEdges: 12\tDistance: 8.47\n",
        "1146\tsd0: 0.35\tsd1: 57.34\tch: -0.072\tEdges: 11\tDistance: 221.79\n",
        " 123\tsd0: 2.71\tsd1: 1.40\tch: -0.124\tEdges: 10\tDistance: 1035.36\n",
        " 127\tsd0: 146.35\tsd1: 21.28\tch: -0.151\tEdges: 3\tDistance: 114.32\n",
        " 150\tsd0: 2.81\tsd1: 0.00\tch: 0.005\tEdges: 3\tDistance: 94.60\n",
        "1274\tsd0: 1.00\tsd1: 29.86\tch: 0.064\tEdges: 10\tDistance: 0.10\n",
        " 334\tsd0: 32.05\tsd1: 0.00\tch: 0.001\tEdges: 1\tDistance: 186.72\n",
        " 924\tsd0: 0.00\tsd1: 0.89\tch: 0.001\tEdges: 1\tDistance: 15.08\n",
        " 995\tsd0: 0.21\tsd1: 0.00\tch: 0.500\tEdges: 3\tDistance: 0.29\n",
        "9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "map(lambda a : a + 5, set([1,2,3]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 23,
       "text": [
        "[6, 7, 8]"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "numpy.cov("
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "SyntaxError",
       "evalue": "unexpected EOF while parsing (<ipython-input-24-c72cada332d7>, line 1)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-24-c72cada332d7>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    numpy.cov(\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
       ]
      }
     ],
     "prompt_number": 24
    }
   ],
   "metadata": {}
  }
 ]
}